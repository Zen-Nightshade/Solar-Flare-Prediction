{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:00:52.363304Z",
     "iopub.status.busy": "2025-11-24T07:00:52.362710Z",
     "iopub.status.idle": "2025-11-24T07:00:52.367832Z",
     "shell.execute_reply": "2025-11-24T07:00:52.366919Z",
     "shell.execute_reply.started": "2025-11-24T07:00:52.363266Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:00:56.612257Z",
     "iopub.status.busy": "2025-11-24T07:00:56.611776Z",
     "iopub.status.idle": "2025-11-24T07:00:56.646789Z",
     "shell.execute_reply": "2025-11-24T07:00:56.645904Z",
     "shell.execute_reply.started": "2025-11-24T07:00:56.612233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected GPU!!!\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "try:\n",
    "    gpu_info = subprocess.check_output(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader'])\n",
    "    print(\"Detected GPU!!!\")\n",
    "    GPU_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    print(f'No GPU Detected. Running on CPU!\\n{e}')\n",
    "    GPU_AVIALABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T06:32:47.912495Z",
     "iopub.status.busy": "2025-11-24T06:32:47.912229Z",
     "iopub.status.idle": "2025-11-24T06:32:58.881236Z",
     "shell.execute_reply": "2025-11-24T06:32:58.880637Z",
     "shell.execute_reply.started": "2025-11-24T06:32:47.912474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-6b2867e4-c8ff-11f0-8030-0242ac130202</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> dask_cuda.LocalCUDACluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">LocalCUDACluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">d999d8a3</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 2\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 2\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 30.00 GiB\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "    <td style=\"text-align: left;\"><strong>Status:</strong> running</td>\n",
       "    <td style=\"text-align: left;\"><strong>Using processes:</strong> True</td>\n",
       "</tr>\n",
       "\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-c2088152-9bc0-4edd-aabf-3f31bd81cdf0</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://127.0.0.1:37707\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 2\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 2\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 30.00 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 0</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:43397\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:44995/status\" target=\"_blank\">http://127.0.0.1:44995/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 15.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:34719\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-3sbwdmvs\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 1</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:38977\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:42957/status\" target=\"_blank\">http://127.0.0.1:42957/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 15.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:34701\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /tmp/dask-scratch-space/worker-ar_tom13\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:37707' processes=2 threads=2, memory=30.00 GiB>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.diagnostics import ProgressBar\n",
    "from dask.distributed import Client\n",
    "\n",
    "cluster = LocalCUDACluster()\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:00:59.752705Z",
     "iopub.status.busy": "2025-11-24T07:00:59.752416Z",
     "iopub.status.idle": "2025-11-24T07:00:59.756869Z",
     "shell.execute_reply": "2025-11-24T07:00:59.756131Z",
     "shell.execute_reply.started": "2025-11-24T07:00:59.752680Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:01:00.784066Z",
     "iopub.status.busy": "2025-11-24T07:01:00.783807Z",
     "iopub.status.idle": "2025-11-24T07:01:00.788418Z",
     "shell.execute_reply": "2025-11-24T07:01:00.787556Z",
     "shell.execute_reply.started": "2025-11-24T07:01:00.784045Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import cudf\n",
    "    import cupy as cp\n",
    "    import dask_cudf\n",
    "    GPU_MODE = torch.cuda.is_available()\n",
    "except ImportError:\n",
    "    cudf = None\n",
    "    cp = None\n",
    "    dask_cudf = None\n",
    "    GPU_MODE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:01:02.123699Z",
     "iopub.status.busy": "2025-11-24T07:01:02.123025Z",
     "iopub.status.idle": "2025-11-24T07:01:02.127809Z",
     "shell.execute_reply": "2025-11-24T07:01:02.126932Z",
     "shell.execute_reply.started": "2025-11-24T07:01:02.123676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set multiprocessing start method to 'spawn'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    torch.multiprocessing.set_start_method('spawn', force=True)\n",
    "    print(\"Set multiprocessing start method to 'spawn'.\")\n",
    "except RuntimeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:01:03.472734Z",
     "iopub.status.busy": "2025-11-24T07:01:03.471981Z",
     "iopub.status.idle": "2025-11-24T07:01:03.476978Z",
     "shell.execute_reply": "2025-11-24T07:01:03.476093Z",
     "shell.execute_reply.started": "2025-11-24T07:01:03.472706Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    balanced_accuracy_score,\n",
    "    matthews_corrcoef,\n",
    "    confusion_matrix\n",
    ")\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:01:06.438649Z",
     "iopub.status.busy": "2025-11-24T07:01:06.438205Z",
     "iopub.status.idle": "2025-11-24T07:01:06.443205Z",
     "shell.execute_reply": "2025-11-24T07:01:06.442565Z",
     "shell.execute_reply.started": "2025-11-24T07:01:06.438626Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dir = \"/kaggle/input/magnetic-data/magnetic_data/train\"\n",
    "dev_dir = \"/kaggle/input/magnetic-data/magnetic_data/dev\"\n",
    "test_dir = \"/kaggle/input/magnetic-data/magnetic_data/test\"\n",
    "scaler_params_path = \"scaler_params.csv\"\n",
    "\n",
    "# CLIENT = Client(n_workers=4, threads_per_worker=2, memory_limit='4GB')\n",
    "# print(f\"Dask Dashboard Link: {CLIENT.dashboard_link}\\n\")\n",
    "\n",
    "features = [\n",
    "    'USFLUX_log', 'TOTPOT_log', 'PIL_LEN_log', 'MEANSHR', 'TOTFZ', 'EPSZ', 'R_VALUE',\n",
    "    'USFLUX_log_roll_mean5', 'USFLUX_log_roll_std5', 'TOTPOT_log_diff1', 'MEANSHR_lag3'\n",
    "]\n",
    "target = 'label'\n",
    "class_names = ['No Flare', 'C-Class', 'M-Class', 'X-Class']\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "num_cpus = os.cpu_count()\n",
    "pin_memory = True\n",
    "load_pre_trained_model = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:01:08.752597Z",
     "iopub.status.busy": "2025-11-24T07:01:08.752267Z",
     "iopub.status.idle": "2025-11-24T07:01:08.758539Z",
     "shell.execute_reply": "2025-11-24T07:01:08.757808Z",
     "shell.execute_reply.started": "2025-11-24T07:01:08.752573Z"
    }
   },
   "outputs": [],
   "source": [
    "def encode_target(ddf, target_col_name):\n",
    "    meta_dict = {col: ddf[col].dtype for col in ddf.columns if col != target_col_name}\n",
    "    meta_dict['flare_level'] = np.int8\n",
    "    \n",
    "    def encode_partition(df):\n",
    "        df['flare_level'] = 0\n",
    "        df.loc[df[target_col_name].str.startswith('C'), 'flare_level'] = 1\n",
    "        df.loc[df[target_col_name].str.startswith('M'), 'flare_level'] = 2\n",
    "        df.loc[df[target_col_name].str.startswith('X'), 'flare_level'] = 3\n",
    "        df['flare_level'] = df['flare_level'].astype(np.int8)\n",
    "        return df.drop(columns=[target_col_name])\n",
    "    \n",
    "    meta_df = pd.DataFrame({col: pd.Series(dtype=dtype) for col, dtype in meta_dict.items()})\n",
    "    \n",
    "    ddf = ddf.map_partitions(encode_partition, meta=meta_df)\n",
    "    \n",
    "    return ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:01:11.461462Z",
     "iopub.status.busy": "2025-11-24T07:01:11.461204Z",
     "iopub.status.idle": "2025-11-24T07:01:11.466054Z",
     "shell.execute_reply": "2025-11-24T07:01:11.465170Z",
     "shell.execute_reply.started": "2025-11-24T07:01:11.461441Z"
    }
   },
   "outputs": [],
   "source": [
    "def Index(ddf):\n",
    "    ddf['safe_index'] = ddf['record_id'].astype(int) * 60 + ddf['seq_id'].astype(int)\n",
    "    ddf = ddf.map_partitions(lambda df: df.sort_values(\"safe_index\"))\n",
    "    ddf = ddf.set_index(\"safe_index\", sorted=False, compute=True)\n",
    "    return ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:01:12.567382Z",
     "iopub.status.busy": "2025-11-24T07:01:12.567126Z",
     "iopub.status.idle": "2025-11-24T07:01:29.427390Z",
     "shell.execute_reply": "2025-11-24T07:01:29.426506Z",
     "shell.execute_reply.started": "2025-11-24T07:01:12.567359Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 07:01:15,008 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 98f34a03f0697fdc39c981d7bb28b9d2 initialized by task ('shuffle-transfer-98f34a03f0697fdc39c981d7bb28b9d2', 2) executed on worker tcp://127.0.0.1:43397\n",
      "2025-11-24 07:01:29,016 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 98f34a03f0697fdc39c981d7bb28b9d2 deactivated due to stimulus 'task-finished-1763967689.011179'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed ddf_train: True\n"
     ]
    }
   ],
   "source": [
    "# train_dir = \"../data/processed/magnetic_data/train/\"\n",
    "ddf_train = dask_cudf.read_parquet(train_dir)\n",
    "# if 'index' in ddf_train.columns:\n",
    "#     ddf_train = ddf_train.drop(columns=['index'])\n",
    "ddf_train = Index(ddf_train)\n",
    "ddf_train = encode_target(ddf_train, target)\n",
    "print(f\"Indexed ddf_train: {ddf_train.index.is_monotonic_increasing.compute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:01:29.428948Z",
     "iopub.status.busy": "2025-11-24T07:01:29.428713Z",
     "iopub.status.idle": "2025-11-24T07:01:30.239942Z",
     "shell.execute_reply": "2025-11-24T07:01:30.239176Z",
     "shell.execute_reply.started": "2025-11-24T07:01:29.428929Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 07:01:29,939 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 653e244e4651b24c2714797d4a8a2022 initialized by task ('shuffle-transfer-653e244e4651b24c2714797d4a8a2022', 3) executed on worker tcp://127.0.0.1:38977\n",
      "2025-11-24 07:01:30,182 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 653e244e4651b24c2714797d4a8a2022 deactivated due to stimulus 'task-finished-1763967690.1805036'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed ddf_dev: True\n"
     ]
    }
   ],
   "source": [
    "# train_dir = \"../data/processed/magnetic_data/train/\"\n",
    "ddf_dev = dask_cudf.read_parquet(dev_dir)\n",
    "ddf_dev = Index(ddf_dev)\n",
    "ddf_dev = encode_target(ddf_dev, target)\n",
    "print(f\"Indexed ddf_dev: {ddf_dev.index.is_monotonic_increasing.compute()}\")\n",
    "\n",
    "# X_train = ddf_train[features].to_dask_array().compute_chunk_sizes()\n",
    "# y_train = ddf_train['flare_level'].to_dask_array().compute_chunk_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:01:30.240861Z",
     "iopub.status.busy": "2025-11-24T07:01:30.240677Z",
     "iopub.status.idle": "2025-11-24T07:01:31.864754Z",
     "shell.execute_reply": "2025-11-24T07:01:31.863742Z",
     "shell.execute_reply.started": "2025-11-24T07:01:30.240846Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 07:01:31,532 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 59bfa0fca3ee7ce3dfd65ae2befc0cd8 initialized by task ('shuffle-transfer-59bfa0fca3ee7ce3dfd65ae2befc0cd8', 3) executed on worker tcp://127.0.0.1:38977\n",
      "2025-11-24 07:01:31,802 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 59bfa0fca3ee7ce3dfd65ae2befc0cd8 deactivated due to stimulus 'task-finished-1763967691.8014262'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed ddf_test: True\n"
     ]
    }
   ],
   "source": [
    "# test_dir = \"../data/processed/magnetic_data/test/\"\n",
    "ddf_test = dask_cudf.read_parquet(test_dir)\n",
    "ddf_test = Index(ddf_test)\n",
    "ddf_test = encode_target(ddf_test, target)\n",
    "print(f\"Indexed ddf_test: {ddf_test.index.is_monotonic_increasing.compute()}\")\n",
    "\n",
    "# X_test = ddf_test[features].to_dask_array().compute_chunk_sizes()\n",
    "# y_test = ddf_test['flare_level'].to_dask_array().compute_chunk_sizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:01:31.866643Z",
     "iopub.status.busy": "2025-11-24T07:01:31.866400Z",
     "iopub.status.idle": "2025-11-24T07:01:44.248757Z",
     "shell.execute_reply": "2025-11-24T07:01:44.247995Z",
     "shell.execute_reply.started": "2025-11-24T07:01:31.866623Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 07:01:32,327 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 98f34a03f0697fdc39c981d7bb28b9d2 initialized by task ('shuffle-transfer-98f34a03f0697fdc39c981d7bb28b9d2', 3) executed on worker tcp://127.0.0.1:38977\n",
      "2025-11-24 07:01:43,629 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 98f34a03f0697fdc39c981d7bb28b9d2 deactivated due to stimulus 'task-finished-1763967703.6277936'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Distribution:\n",
      "flare_level\n",
      "0    11042040\n",
      "1     1236240\n",
      "2      227100\n",
      "3       22620\n",
      "Name: count, dtype: int64\n",
      "Note the mapping: 0=No Flare, 1=C-Class, 2=M-Class, 3=X-Class\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_gpu = ddf_train[['flare_level']].compute()  # Bring to a single CuDF on GPU\n",
    "class_counts_multi = df_gpu['flare_level'].value_counts()\n",
    "print(f\"Multiclass Distribution:\\n{class_counts_multi}\")\n",
    "print(\"Note the mapping: 0=No Flare, 1=C-Class, 2=M-Class, 3=X-Class\\n\")\n",
    "class_counts = class_counts_multi.sort_index()\n",
    "total = class_counts.sum()\n",
    "class_weights = total / (len(class_counts) * class_counts)\n",
    "class_weights_tensor = torch.tensor(class_weights.values, dtype=torch.float32).to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:01:44.249626Z",
     "iopub.status.busy": "2025-11-24T07:01:44.249387Z",
     "iopub.status.idle": "2025-11-24T07:01:55.751774Z",
     "shell.execute_reply": "2025-11-24T07:01:55.751180Z",
     "shell.execute_reply.started": "2025-11-24T07:01:44.249609Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 07:01:44,674 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 98f34a03f0697fdc39c981d7bb28b9d2 initialized by task ('shuffle-transfer-98f34a03f0697fdc39c981d7bb28b9d2', 2) executed on worker tcp://127.0.0.1:43397\n",
      "2025-11-24 07:01:55,332 - distributed.shuffle._scheduler_plugin - WARNING - Shuffle 98f34a03f0697fdc39c981d7bb28b9d2 deactivated due to stimulus 'task-finished-1763967715.3306108'\n"
     ]
    }
   ],
   "source": [
    "aggregations = {col: ['mean', 'std'] for col in features if col not in ['record_id', 'seq_id']}\n",
    "scaler_params_df = (\n",
    "    ddf_train.map_partitions(\n",
    "        lambda gdf: gdf.groupby(\"seq_id\").agg(aggregations)\n",
    "    ).compute()\n",
    ")\n",
    "\n",
    "scaler_params_df.columns = ['_'.join(col).strip() for col in scaler_params_df.columns.values]\n",
    "scaler_params_df.to_csv(scaler_params_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:01:55.752719Z",
     "iopub.status.busy": "2025-11-24T07:01:55.752460Z",
     "iopub.status.idle": "2025-11-24T07:01:55.758419Z",
     "shell.execute_reply": "2025-11-24T07:01:55.757674Z",
     "shell.execute_reply.started": "2025-11-24T07:01:55.752693Z"
    }
   },
   "outputs": [],
   "source": [
    "def timeseries_scaling(ddf, scaler_params_path, features):\n",
    "    if isinstance(ddf, dd.DataFrame):\n",
    "        ddf = dask_cudf.from_cudf(ddf.compute(), npartitions=ddf.npartitions)\n",
    "\n",
    "    scaler_params = cudf.read_csv(scaler_params_path)\n",
    "    scaler_params_ddf = dask_cudf.from_cudf(scaler_params, npartitions=1)\n",
    "\n",
    "    ddf_scaled = ddf.merge(scaler_params_ddf, on=\"seq_id\", how=\"left\")\n",
    "\n",
    "    for col in features:\n",
    "        mean_col = f\"{col}_mean\"\n",
    "        std_col = f\"{col}_std\"\n",
    "        ddf_scaled[col] = (ddf_scaled[col] - ddf_scaled[mean_col]) / (ddf_scaled[std_col] + 1e-7)\n",
    "\n",
    "    return ddf_scaled.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_train = timeseries_scaling(ddf_train, scaler_params_path, features).persist()\n",
    "ddf_dev = timeseries_scaling(ddf_dev, scaler_params_path, features).persist()\n",
    "ddf_test = timeseries_scaling(ddf_test, scaler_params_path, features).persist()\n",
    "# ddf_train.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T21:27:30.630435Z",
     "iopub.status.busy": "2025-11-09T21:27:30.630124Z",
     "iopub.status.idle": "2025-11-09T21:27:30.975144Z",
     "shell.execute_reply": "2025-11-09T21:27:30.973867Z",
     "shell.execute_reply.started": "2025-11-09T21:27:30.630414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  9 21:27:30 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   75C    P0             34W /   70W |    9277MiB /  15360MiB |      2%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n",
      "| N/A   65C    P0             29W /   70W |    7629MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:02:21.641119Z",
     "iopub.status.busy": "2025-11-24T07:02:21.640910Z",
     "iopub.status.idle": "2025-11-24T07:02:21.654288Z",
     "shell.execute_reply": "2025-11-24T07:02:21.653207Z",
     "shell.execute_reply.started": "2025-11-24T07:02:21.641103Z"
    }
   },
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, ddf, features=features, target=\"flare_level\", chunk_size=10000):\n",
    "        self.features_col = features\n",
    "        self.target = target\n",
    "        seq_length = 60\n",
    "        num_features = len(features)\n",
    "        \n",
    "        unique_ids_series = ddf[\"record_id\"].unique().compute()\n",
    "        \n",
    "        if hasattr(unique_ids_series, 'to_arrow'):\n",
    "            record_list = unique_ids_series.to_arrow().to_pylist()\n",
    "        elif hasattr(unique_ids_series, 'to_pandas'):\n",
    "            record_list = unique_ids_series.to_pandas().tolist()\n",
    "        else:\n",
    "            record_list = list(unique_ids_series)\n",
    "        \n",
    "        num_records = len(record_list)        \n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        \n",
    "        num_chunks = (num_records + chunk_size - 1) // chunk_size\n",
    "        \n",
    "        for chunk_idx in range(num_chunks):\n",
    "            start_idx = chunk_idx * chunk_size\n",
    "            end_idx = min(start_idx + chunk_size, num_records)\n",
    "            chunk_records = record_list[start_idx:end_idx]\n",
    "            \n",
    "            try:\n",
    "                chunk_ddf = ddf[ddf[\"record_id\"].isin(chunk_records)]\n",
    "                chunk_df = chunk_ddf.compute()\n",
    "                \n",
    "                if hasattr(chunk_df, 'to_pandas'):\n",
    "                    chunk_df = chunk_df.to_pandas()\n",
    "                \n",
    "                grouped = chunk_df.groupby(\"record_id\")\n",
    "                \n",
    "                for record_id, seq_df in grouped:\n",
    "                    # actual_len = len(seq_df)\n",
    "                    \n",
    "                    # if actual_len != seq_length and len(self.X) < 5:\n",
    "                    #     print(f\"\\t\\tRecord {record_id}: {actual_len} rows (expected {seq_length})\")\n",
    "                    \n",
    "                    # if actual_len >= seq_length:\n",
    "                    #     seq_df = seq_df.iloc[:seq_length]\n",
    "                    # else:\n",
    "                    #     continue\n",
    "                    \n",
    "                    try:\n",
    "                        features_array = seq_df[self.features_col].values.astype(np.float32)\n",
    "                        target_value = seq_df[self.target].mode().iloc[0]\n",
    "                        \n",
    "                        self.X.append(features_array)\n",
    "                        self.y.append(target_value)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        if len(self.X) < 3:\n",
    "                            print(f\"ERROR: {e}\")\n",
    "                        continue\n",
    "                \n",
    "                del chunk_df, chunk_ddf\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"CHUNK ERROR: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if len(self.X) == 0:\n",
    "            raise ValueError(\"No sequences loaded! Check preprocessing pipeline.\")\n",
    "        \n",
    "        self.X = np.array(self.X, dtype=np.float32)\n",
    "        self.y = np.array(self.y, dtype=np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.from_numpy(self.X[idx]),\n",
    "            torch.tensor(self.y[idx], dtype=torch.long)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:02:21.655586Z",
     "iopub.status.busy": "2025-11-24T07:02:21.655314Z",
     "iopub.status.idle": "2025-11-24T07:02:21.681359Z",
     "shell.execute_reply": "2025-11-24T07:02:21.680354Z",
     "shell.execute_reply.started": "2025-11-24T07:02:21.655564Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_dataloader(dataset, batch_size=64, shuffle=True):\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=0,\n",
    "        pin_memory=not GPU_MODE,\n",
    "        prefetch_factor=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TimeSeriesDataset(ddf_train.persist())\n",
    "train = make_dataloader(train_dataset)\n",
    "\n",
    "dev_dataset = TimeSeriesDataset(ddf_dev.persist())\n",
    "dev = make_dataloader(dev_dataset)\n",
    "\n",
    "test_dataset = TimeSeriesDataset(ddf_test.persist())\n",
    "test = make_dataloader(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attentive RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:06:10.910730Z",
     "iopub.status.busy": "2025-11-24T07:06:10.910408Z",
     "iopub.status.idle": "2025-11-24T07:06:10.923642Z",
     "shell.execute_reply": "2025-11-24T07:06:10.922325Z",
     "shell.execute_reply.started": "2025-11-24T07:06:10.910704Z"
    }
   },
   "outputs": [],
   "source": [
    "class AttentiveRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, attention = False, bidirectional = False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        if attention in [\"dot\", \"concat\", None]:\n",
    "            self.attention = attention\n",
    "        else:\n",
    "            raise ValueError(\"attention can only be 'dot' or 'concat'!!!\")\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first = True, bidirectional = bidirectional)\n",
    "        self.concat = nn.Linear(hidden_size * self.num_directions, 1)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size * self.num_directions, num_classes)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # X shape: (batch_size, seq_len, input_size)\n",
    "        batch_size, seq_len, input_size = X.shape\n",
    "        rnn_out, h_n = self.rnn(X)\n",
    "        # rnn_output: (batch_size, seq_len, hidden_size * num_directions)\n",
    "        # h_n: (num_layers * num_directions, batch_size, hidden_size)\n",
    "        score = None\n",
    "        if self.attention == \"concat\":\n",
    "            atten_input = rnn_out.reshape(-1, self.hidden_size * self.num_directions)     # (batch_size * seq-Len, hidden_size * num_directons)\n",
    "            score = self.concat(atten_input).view(batch_size, -1)                         # (batch_size, seq_len)\n",
    "        \n",
    "        elif self.attention == \"dot\":\n",
    "            \n",
    "            if self.num_directions == 2:\n",
    "                last_hidden = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1)\n",
    "            else:\n",
    "                last_hidden = h_n[-1,:,:]\n",
    "        \n",
    "            query = last_hidden.unsqueeze(1)                                              # (batch_size, 1, hidden_size * num_directions)\n",
    "            score = torch.bmm(query, rnn_out.transpose(1,2)).squeeze(1)                   # (batch_size, seq_len)\n",
    "        \n",
    "        context = None\n",
    "        attn_weights = None\n",
    "        \n",
    "        if score is not None:\n",
    "            attn_weights = F.softmax(score, dim=1)                                       # (batch_size, seq_len)\n",
    "            context = torch.bmm(attn_weights.unsqueeze(1), rnn_out)                       # (batch_size, 1, hidden_size * num_directions)\n",
    "            context = context.squeeze(1)                                                  # (batch_size, hidden_size * num_directions)\n",
    "        else:\n",
    "            if self.num_directions == 2:\n",
    "                context = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1)\n",
    "            else:\n",
    "                context = h_n[-1,:,:]\n",
    "\n",
    "        output = self.fc(context)\n",
    "        \n",
    "        return output, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attentive LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:06:10.924911Z",
     "iopub.status.busy": "2025-11-24T07:06:10.924564Z",
     "iopub.status.idle": "2025-11-24T07:06:10.937923Z",
     "shell.execute_reply": "2025-11-24T07:06:10.937007Z",
     "shell.execute_reply.started": "2025-11-24T07:06:10.924884Z"
    }
   },
   "outputs": [],
   "source": [
    "class AttentiveLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, attention=None, bidirectional=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        if attention in [\"dot\", \"concat\", None]:\n",
    "            self.attention = attention\n",
    "        else:\n",
    "            raise ValueError(\"attention can only be 'dot', 'concat', or None!!!\")\n",
    "        \n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=bidirectional)\n",
    "        \n",
    "        if self.attention == \"concat\":\n",
    "            self.attention_layer = nn.Linear(hidden_size * self.num_directions, 1)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size * self.num_directions, num_classes)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # X shape: (batch_size, seq_len, input_size)\n",
    "        batch_size, seq_len, _ = X.shape\n",
    "        \n",
    "        lstm_out, (h_n, c_n) = self.lstm(X)\n",
    "        # lstm_out: (batch_size, seq_len, hidden_size * num_directions)\n",
    "        # h_n: (num_layers * num_directions, batch_size, hidden_size)\n",
    "        # c_n: (num_layers * num_directions, batch_size, hidden_size)\n",
    "        \n",
    "        score = None\n",
    "        if self.attention == \"concat\":\n",
    "            atten_input = lstm_out.reshape(-1, self.hidden_size * self.num_directions)\n",
    "            score = self.attention_layer(atten_input).view(batch_size, -1)\n",
    "        \n",
    "        elif self.attention == \"dot\":\n",
    "            if self.num_directions == 2:\n",
    "                last_hidden = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1)\n",
    "            else:\n",
    "                last_hidden = h_n[-1,:,:]\n",
    "        \n",
    "            query = last_hidden.unsqueeze(1)\n",
    "            score = torch.bmm(query, lstm_out.transpose(1,2)).squeeze(1)\n",
    "        \n",
    "        context = None\n",
    "        attn_weights = None\n",
    "        \n",
    "        if self.attention is not None:\n",
    "            attn_weights = F.softmax(score, dim=1)\n",
    "            context = torch.bmm(attn_weights.unsqueeze(1), lstm_out)\n",
    "            context = context.squeeze(1)\n",
    "        else:\n",
    "            if self.num_directions == 2:\n",
    "                context = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1)\n",
    "            else:\n",
    "                context = h_n[-1,:,:]\n",
    "\n",
    "        output = self.fc(context)\n",
    "        \n",
    "        return output, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:06:10.939000Z",
     "iopub.status.busy": "2025-11-24T07:06:10.938706Z",
     "iopub.status.idle": "2025-11-24T07:06:10.952315Z",
     "shell.execute_reply": "2025-11-24T07:06:10.951750Z",
     "shell.execute_reply.started": "2025-11-24T07:06:10.938983Z"
    }
   },
   "outputs": [],
   "source": [
    "def training(model, device, criterion, optimizer, train_loader, train_epochs=10, pre_epochs=0):\n",
    "    print(f\"Starting training for {train_epochs} epochs on {device}.\")\n",
    "    train_start = time.time()\n",
    "    epoch_pbar = tqdm(range(train_epochs), desc=\"Training Progress\", unit=\"epoch\")\n",
    "    \n",
    "    for epoch in epoch_pbar:\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        all_predictions = []\n",
    "        all_targets = []\n",
    "        \n",
    "        for features, labels in train_loader:\n",
    "            features = features.to(device) \n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits, _ = model(features)\n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted_classes = torch.max(logits, 1)\n",
    "            all_predictions.extend(predicted_classes.cpu().numpy())\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        accuracy = accuracy_score(all_targets, all_predictions)\n",
    "        \n",
    "        print(f\"Epoch {pre_epochs + epoch + 1} Summary -> Avg. Loss: {avg_loss:.4f}, Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "    total_seconds = time.time() - train_start\n",
    "    hours, rem = divmod(total_seconds, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    print(f\"\\nTotal Train Time: {int(hours)}h {int(minutes)}m {int(seconds)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:06:10.953322Z",
     "iopub.status.busy": "2025-11-24T07:06:10.953076Z",
     "iopub.status.idle": "2025-11-24T07:06:10.966383Z",
     "shell.execute_reply": "2025-11-24T07:06:10.965610Z",
     "shell.execute_reply.started": "2025-11-24T07:06:10.953300Z"
    }
   },
   "outputs": [],
   "source": [
    "def eval_detailed(model, device, loader, report_title=\"Evaluation\"):\n",
    "    model.eval()\n",
    "    all_targets, all_predictions, all_probas = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels in tqdm(loader, desc=f\"Evaluating ({report_title})\", leave=False):\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            logits, _ = model(features)\n",
    "            probas = F.softmax(logits, dim=1)\n",
    "            preds = torch.argmax(probas, dim=1)\n",
    "\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(preds.cpu().numpy())\n",
    "            all_probas.extend(probas.cpu().numpy())\n",
    "\n",
    "    y_true = np.array(all_targets)\n",
    "    y_pred = np.array(all_predictions)\n",
    "    y_pred_proba = np.array(all_probas)\n",
    "\n",
    "    print(f\"\\n================= {report_title} =================\")\n",
    "    print(\"Classification Report:\\n\")\n",
    "    print(classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        target_names=class_names,\n",
    "        digits=4,\n",
    "        zero_division=0\n",
    "    ))\n",
    "\n",
    "    try:\n",
    "        roc_auc = roc_auc_score(y_true, y_pred_proba, multi_class='ovr', average='weighted')\n",
    "    except ValueError:\n",
    "        roc_auc = float(\"nan\")\n",
    "\n",
    "    metrics = {\n",
    "        \"balanced_accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
    "        \"roc_auc_weighted\": roc_auc,\n",
    "        \"mcc\": matthews_corrcoef(y_true, y_pred),\n",
    "        \"f1_macro\": f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        \"f1_weighted\": f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    }\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "    print(\"\\nNormalized Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    print(\"\\nKey Metrics Summary:\")\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"  {k:20s}: {v:.4f}\")\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T07:34:42.952866Z",
     "iopub.status.busy": "2025-11-10T07:34:42.952663Z",
     "iopub.status.idle": "2025-11-10T07:34:42.973297Z",
     "shell.execute_reply": "2025-11-10T07:34:42.972304Z",
     "shell.execute_reply.started": "2025-11-10T07:34:42.952850Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model_as_zip(model, model_name, save_dir=\"/kaggle/working\"):\n",
    "    # File paths\n",
    "    model_path = os.path.join(save_dir, f\"{model_name}.pth\")\n",
    "    zip_path = os.path.join(save_dir, f\"{model_name}.zip\")\n",
    "\n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    # Zip it\n",
    "    with zipfile.ZipFile(zip_path, 'w', compression=zipfile.ZIP_DEFLATED) as zipf:\n",
    "        zipf.write(model_path, arcname=f\"{model_name}.pth\")\n",
    "\n",
    "    # Remove unzipped .pth file\n",
    "    os.remove(model_path)\n",
    "\n",
    "    # Get zipped size in MB\n",
    "    size_bytes = os.path.getsize(zip_path)\n",
    "    size_mb = size_bytes / (1024 ** 2)\n",
    "\n",
    "    print(f\"{model_name}.zip saved at {zip_path} | Size: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T21:32:38.993222Z",
     "iopub.status.busy": "2025-11-09T21:32:38.992947Z",
     "iopub.status.idle": "2025-11-09T21:32:39.005910Z",
     "shell.execute_reply": "2025-11-09T21:32:39.005371Z",
     "shell.execute_reply.started": "2025-11-09T21:32:38.993198Z"
    }
   },
   "outputs": [],
   "source": [
    "experiments = []\n",
    "model_types = [\"RNN\", \"LSTM\"]\n",
    "attention_types = [None, \"dot\", \"concat\"]\n",
    "directionality = [False, True]\n",
    "\n",
    "for model_t in model_types:\n",
    "    for att_t in attention_types:\n",
    "        for is_bi in directionality:\n",
    "            # Create a descriptive name for the run\n",
    "            direction_str = \"Bi\" if is_bi else \"Uni\"\n",
    "            attention_str = att_t if att_t is not None else \"NoAtt\"\n",
    "            run_name = f\"{model_t}_{direction_str}_{attention_str}\"\n",
    "            \n",
    "            config = {\n",
    "                \"run_name\": run_name,\n",
    "                \"model_type\": model_t,\n",
    "                \"hidden_size\": 128,\n",
    "                \"num_layers\": 2,\n",
    "                \"attention\": att_t,\n",
    "                \"bidirectional\": is_bi,\n",
    "                \"lr\": 0.001,\n",
    "                \"epochs\": 60\n",
    "            }\n",
    "            experiments.append(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-09T21:32:39.007266Z",
     "iopub.status.busy": "2025-11-09T21:32:39.007013Z",
     "iopub.status.idle": "2025-11-10T04:55:16.975631Z",
     "shell.execute_reply": "2025-11-10T04:55:16.974961Z",
     "shell.execute_reply.started": "2025-11-09T21:32:39.007245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== Experiment 1/12: RNN_Uni_NoAtt ==============================\n",
      "Using 2 GPUs via DataParallel!\n",
      "Training model: RNN_Uni_NoAtt for 60 epochs...\n",
      "Starting training for 60 epochs on cuda.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "108644c2efdf4c8daa1835ef9abe6e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/60 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Summary -> Avg. Loss: 0.8937, Accuracy: 74.97%\n",
      "Epoch 2 Summary -> Avg. Loss: 0.8696, Accuracy: 74.98%\n",
      "Epoch 3 Summary -> Avg. Loss: 0.8531, Accuracy: 74.35%\n",
      "Epoch 4 Summary -> Avg. Loss: 0.8517, Accuracy: 74.64%\n",
      "Epoch 5 Summary -> Avg. Loss: 0.8438, Accuracy: 74.53%\n",
      "Epoch 6 Summary -> Avg. Loss: 0.8540, Accuracy: 74.18%\n",
      "Epoch 7 Summary -> Avg. Loss: 0.9433, Accuracy: 72.51%\n",
      "Epoch 8 Summary -> Avg. Loss: 0.8693, Accuracy: 75.24%\n",
      "Epoch 9 Summary -> Avg. Loss: 0.8577, Accuracy: 74.73%\n",
      "Epoch 10 Summary -> Avg. Loss: 0.8692, Accuracy: 73.64%\n",
      "Epoch 11 Summary -> Avg. Loss: 0.8580, Accuracy: 73.41%\n",
      "Epoch 12 Summary -> Avg. Loss: 0.8534, Accuracy: 74.13%\n",
      "Epoch 13 Summary -> Avg. Loss: 0.8591, Accuracy: 74.06%\n",
      "Epoch 14 Summary -> Avg. Loss: 0.8486, Accuracy: 75.31%\n",
      "Epoch 15 Summary -> Avg. Loss: 0.8425, Accuracy: 74.59%\n",
      "Epoch 16 Summary -> Avg. Loss: 0.8526, Accuracy: 75.08%\n",
      "Epoch 17 Summary -> Avg. Loss: 0.8467, Accuracy: 75.10%\n",
      "Epoch 18 Summary -> Avg. Loss: 0.8455, Accuracy: 74.53%\n",
      "Epoch 19 Summary -> Avg. Loss: 0.8465, Accuracy: 74.98%\n",
      "Epoch 20 Summary -> Avg. Loss: 0.8456, Accuracy: 74.24%\n",
      "Epoch 21 Summary -> Avg. Loss: 0.8343, Accuracy: 75.39%\n",
      "Epoch 22 Summary -> Avg. Loss: 0.8460, Accuracy: 74.59%\n",
      "Epoch 23 Summary -> Avg. Loss: 0.8563, Accuracy: 74.81%\n",
      "Epoch 24 Summary -> Avg. Loss: 0.8393, Accuracy: 74.76%\n",
      "Epoch 25 Summary -> Avg. Loss: 0.8561, Accuracy: 74.66%\n",
      "Epoch 26 Summary -> Avg. Loss: 0.8445, Accuracy: 75.49%\n",
      "Epoch 27 Summary -> Avg. Loss: 0.8392, Accuracy: 75.06%\n",
      "Epoch 28 Summary -> Avg. Loss: 0.8484, Accuracy: 75.29%\n",
      "Epoch 29 Summary -> Avg. Loss: 0.8690, Accuracy: 75.23%\n",
      "Epoch 30 Summary -> Avg. Loss: 0.8469, Accuracy: 75.14%\n",
      "Epoch 31 Summary -> Avg. Loss: 0.8483, Accuracy: 74.52%\n",
      "Epoch 32 Summary -> Avg. Loss: 0.8524, Accuracy: 75.13%\n",
      "Epoch 33 Summary -> Avg. Loss: 0.8332, Accuracy: 76.17%\n",
      "Epoch 34 Summary -> Avg. Loss: 0.8336, Accuracy: 76.10%\n",
      "Epoch 35 Summary -> Avg. Loss: 0.8621, Accuracy: 76.06%\n",
      "Epoch 36 Summary -> Avg. Loss: 0.8388, Accuracy: 75.72%\n",
      "Epoch 37 Summary -> Avg. Loss: 0.9080, Accuracy: 73.57%\n",
      "Epoch 38 Summary -> Avg. Loss: 0.8559, Accuracy: 75.36%\n",
      "Epoch 39 Summary -> Avg. Loss: 0.8645, Accuracy: 75.46%\n",
      "Epoch 40 Summary -> Avg. Loss: 0.8585, Accuracy: 74.25%\n",
      "Epoch 41 Summary -> Avg. Loss: 0.8512, Accuracy: 75.35%\n",
      "Epoch 42 Summary -> Avg. Loss: 0.8476, Accuracy: 75.10%\n",
      "Epoch 43 Summary -> Avg. Loss: 0.8529, Accuracy: 75.27%\n",
      "Epoch 44 Summary -> Avg. Loss: 0.8674, Accuracy: 74.30%\n",
      "Epoch 45 Summary -> Avg. Loss: 0.8903, Accuracy: 72.96%\n",
      "Epoch 46 Summary -> Avg. Loss: 0.8806, Accuracy: 74.94%\n",
      "Epoch 47 Summary -> Avg. Loss: 0.8589, Accuracy: 74.22%\n",
      "Epoch 48 Summary -> Avg. Loss: 0.8515, Accuracy: 75.24%\n",
      "Epoch 49 Summary -> Avg. Loss: 0.8536, Accuracy: 75.26%\n",
      "Epoch 50 Summary -> Avg. Loss: 0.8465, Accuracy: 75.00%\n",
      "Epoch 51 Summary -> Avg. Loss: 0.8384, Accuracy: 74.81%\n",
      "Epoch 52 Summary -> Avg. Loss: 0.8459, Accuracy: 75.16%\n",
      "Epoch 53 Summary -> Avg. Loss: 0.8371, Accuracy: 75.28%\n",
      "Epoch 54 Summary -> Avg. Loss: 0.8363, Accuracy: 75.79%\n",
      "Epoch 55 Summary -> Avg. Loss: 0.8381, Accuracy: 74.76%\n",
      "Epoch 56 Summary -> Avg. Loss: 0.8550, Accuracy: 74.81%\n",
      "Epoch 57 Summary -> Avg. Loss: 0.8445, Accuracy: 75.51%\n",
      "Epoch 58 Summary -> Avg. Loss: 0.8604, Accuracy: 75.20%\n",
      "Epoch 59 Summary -> Avg. Loss: 0.8479, Accuracy: 73.95%\n",
      "Epoch 60 Summary -> Avg. Loss: 0.8383, Accuracy: 73.48%\n",
      "\n",
      "Total Train Time: 0h 23m 32s\n",
      "Evaluating model: RNN_Uni_NoAtt...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating (RNN_Uni_NoAtt):   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= RNN_Uni_NoAtt =================\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Flare     0.9781    0.8072    0.8845      1878\n",
      "     C-Class     0.2725    0.6619    0.3861       210\n",
      "     M-Class     0.2429    0.4359    0.3119        39\n",
      "     X-Class     0.0000    0.0000    0.0000         4\n",
      "\n",
      "    accuracy                         0.7846      2131\n",
      "   macro avg     0.3734    0.4763    0.3956      2131\n",
      "weighted avg     0.8932    0.7846    0.8232      2131\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix:\n",
      " [[8.07241747e-01 1.85303514e-01 6.92225772e-03 5.32481363e-04]\n",
      " [1.57142857e-01 6.61904762e-01 1.80952381e-01 0.00000000e+00]\n",
      " [2.56410256e-02 5.38461538e-01 4.35897436e-01 0.00000000e+00]\n",
      " [0.00000000e+00 5.00000000e-01 5.00000000e-01 0.00000000e+00]]\n",
      "\n",
      "Key Metrics Summary:\n",
      "  balanced_accuracy   : 0.4763\n",
      "  roc_auc_weighted    : 0.9026\n",
      "  mcc                 : 0.4025\n",
      "  f1_macro            : 0.3956\n",
      "  f1_weighted         : 0.8232\n",
      "RNN_Uni_NoAtt.zip saved at /kaggle/working/RNN_Uni_NoAtt.zip | Size: 0.18 MB\n",
      "\n",
      "============================== Experiment 2/12: RNN_Bi_NoAtt ==============================\n",
      "Using 2 GPUs via DataParallel!\n",
      "Training model: RNN_Bi_NoAtt for 60 epochs...\n",
      "Starting training for 60 epochs on cuda.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da693ed3b20424396460a259a7f39fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/60 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Summary -> Avg. Loss: 0.8980, Accuracy: 75.19%\n",
      "Epoch 2 Summary -> Avg. Loss: 0.8642, Accuracy: 75.45%\n",
      "Epoch 3 Summary -> Avg. Loss: 0.8498, Accuracy: 75.62%\n",
      "Epoch 4 Summary -> Avg. Loss: 0.8441, Accuracy: 75.96%\n",
      "Epoch 5 Summary -> Avg. Loss: 0.8369, Accuracy: 76.32%\n",
      "Epoch 6 Summary -> Avg. Loss: 0.8266, Accuracy: 76.27%\n",
      "Epoch 7 Summary -> Avg. Loss: 0.8167, Accuracy: 76.40%\n",
      "Epoch 8 Summary -> Avg. Loss: 0.8083, Accuracy: 76.35%\n",
      "Epoch 9 Summary -> Avg. Loss: 0.8037, Accuracy: 76.07%\n",
      "Epoch 10 Summary -> Avg. Loss: 0.8087, Accuracy: 76.07%\n",
      "Epoch 11 Summary -> Avg. Loss: 0.7983, Accuracy: 76.23%\n",
      "Epoch 12 Summary -> Avg. Loss: 0.7960, Accuracy: 76.09%\n",
      "Epoch 13 Summary -> Avg. Loss: 0.8112, Accuracy: 75.87%\n",
      "Epoch 14 Summary -> Avg. Loss: 0.7909, Accuracy: 76.04%\n",
      "Epoch 15 Summary -> Avg. Loss: 0.7837, Accuracy: 76.38%\n",
      "Epoch 16 Summary -> Avg. Loss: 0.7856, Accuracy: 76.59%\n",
      "Epoch 17 Summary -> Avg. Loss: 0.7767, Accuracy: 76.62%\n",
      "Epoch 18 Summary -> Avg. Loss: 0.7956, Accuracy: 76.31%\n",
      "Epoch 19 Summary -> Avg. Loss: 0.7922, Accuracy: 76.21%\n",
      "Epoch 20 Summary -> Avg. Loss: 0.7728, Accuracy: 76.46%\n",
      "Epoch 21 Summary -> Avg. Loss: 0.8006, Accuracy: 76.40%\n",
      "Epoch 22 Summary -> Avg. Loss: 0.7935, Accuracy: 76.52%\n",
      "Epoch 23 Summary -> Avg. Loss: 0.7780, Accuracy: 76.96%\n",
      "Epoch 24 Summary -> Avg. Loss: 0.7741, Accuracy: 76.65%\n",
      "Epoch 25 Summary -> Avg. Loss: 0.7655, Accuracy: 76.48%\n",
      "Epoch 26 Summary -> Avg. Loss: 0.7642, Accuracy: 76.52%\n",
      "Epoch 27 Summary -> Avg. Loss: 0.7682, Accuracy: 76.37%\n",
      "Epoch 28 Summary -> Avg. Loss: 0.7606, Accuracy: 76.57%\n",
      "Epoch 29 Summary -> Avg. Loss: 0.7827, Accuracy: 76.34%\n",
      "Epoch 30 Summary -> Avg. Loss: 0.7725, Accuracy: 76.29%\n",
      "Epoch 31 Summary -> Avg. Loss: 0.7815, Accuracy: 76.87%\n",
      "Epoch 32 Summary -> Avg. Loss: 0.7748, Accuracy: 76.91%\n",
      "Epoch 33 Summary -> Avg. Loss: 0.7816, Accuracy: 76.83%\n",
      "Epoch 34 Summary -> Avg. Loss: 0.7634, Accuracy: 76.62%\n",
      "Epoch 35 Summary -> Avg. Loss: 0.7598, Accuracy: 76.54%\n",
      "Epoch 36 Summary -> Avg. Loss: 0.7698, Accuracy: 76.68%\n",
      "Epoch 37 Summary -> Avg. Loss: 0.7624, Accuracy: 76.43%\n",
      "Epoch 38 Summary -> Avg. Loss: 0.7429, Accuracy: 77.00%\n",
      "Epoch 39 Summary -> Avg. Loss: 0.7434, Accuracy: 77.05%\n",
      "Epoch 40 Summary -> Avg. Loss: 0.7480, Accuracy: 76.91%\n",
      "Epoch 41 Summary -> Avg. Loss: 0.7739, Accuracy: 76.82%\n",
      "Epoch 42 Summary -> Avg. Loss: 0.7692, Accuracy: 76.97%\n",
      "Epoch 43 Summary -> Avg. Loss: 0.7548, Accuracy: 77.05%\n",
      "Epoch 44 Summary -> Avg. Loss: 0.7504, Accuracy: 76.99%\n",
      "Epoch 45 Summary -> Avg. Loss: 0.7388, Accuracy: 77.34%\n",
      "Epoch 46 Summary -> Avg. Loss: 0.7507, Accuracy: 77.03%\n",
      "Epoch 47 Summary -> Avg. Loss: 0.7719, Accuracy: 76.26%\n",
      "Epoch 48 Summary -> Avg. Loss: 0.7759, Accuracy: 75.99%\n",
      "Epoch 49 Summary -> Avg. Loss: 0.7566, Accuracy: 76.47%\n",
      "Epoch 50 Summary -> Avg. Loss: 0.7487, Accuracy: 76.59%\n",
      "Epoch 51 Summary -> Avg. Loss: 0.7572, Accuracy: 76.72%\n",
      "Epoch 52 Summary -> Avg. Loss: 0.7466, Accuracy: 76.75%\n",
      "Epoch 53 Summary -> Avg. Loss: 0.7521, Accuracy: 77.03%\n",
      "Epoch 54 Summary -> Avg. Loss: 0.7498, Accuracy: 76.73%\n",
      "Epoch 55 Summary -> Avg. Loss: 0.7512, Accuracy: 76.88%\n",
      "Epoch 56 Summary -> Avg. Loss: 0.7502, Accuracy: 76.74%\n",
      "Epoch 57 Summary -> Avg. Loss: 0.7426, Accuracy: 77.26%\n",
      "Epoch 58 Summary -> Avg. Loss: 0.7396, Accuracy: 76.82%\n",
      "Epoch 59 Summary -> Avg. Loss: 0.7447, Accuracy: 76.92%\n",
      "Epoch 60 Summary -> Avg. Loss: 0.7480, Accuracy: 77.15%\n",
      "\n",
      "Total Train Time: 0h 27m 38s\n",
      "Evaluating model: RNN_Bi_NoAtt...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating (RNN_Bi_NoAtt):   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= RNN_Bi_NoAtt =================\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Flare     0.9894    0.7455    0.8503      1878\n",
      "     C-Class     0.2365    0.6048    0.3400       210\n",
      "     M-Class     0.1486    0.5641    0.2353        39\n",
      "     X-Class     0.0645    0.5000    0.1143         4\n",
      "\n",
      "    accuracy                         0.7278      2131\n",
      "   macro avg     0.3598    0.6036    0.3850      2131\n",
      "weighted avg     0.8981    0.7278    0.7874      2131\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix:\n",
      " [[0.74547391 0.2113951  0.04153355 0.00159744]\n",
      " [0.07142857 0.6047619  0.21904762 0.1047619 ]\n",
      " [0.         0.33333333 0.56410256 0.1025641 ]\n",
      " [0.         0.         0.5        0.5       ]]\n",
      "\n",
      "Key Metrics Summary:\n",
      "  balanced_accuracy   : 0.6036\n",
      "  roc_auc_weighted    : 0.9065\n",
      "  mcc                 : 0.3602\n",
      "  f1_macro            : 0.3850\n",
      "  f1_weighted         : 0.7874\n",
      "RNN_Bi_NoAtt.zip saved at /kaggle/working/RNN_Bi_NoAtt.zip | Size: 0.48 MB\n",
      "\n",
      "============================== Experiment 3/12: RNN_Uni_dot ==============================\n",
      "Using 2 GPUs via DataParallel!\n",
      "Training model: RNN_Uni_dot for 60 epochs...\n",
      "Starting training for 60 epochs on cuda.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b693bae8f6405890296deed4064557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/60 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Summary -> Avg. Loss: 0.8832, Accuracy: 75.52%\n",
      "Epoch 2 Summary -> Avg. Loss: 0.8972, Accuracy: 73.76%\n",
      "Epoch 3 Summary -> Avg. Loss: 0.8909, Accuracy: 74.16%\n",
      "Epoch 4 Summary -> Avg. Loss: 0.8866, Accuracy: 73.27%\n",
      "Epoch 5 Summary -> Avg. Loss: 0.8629, Accuracy: 75.34%\n",
      "Epoch 6 Summary -> Avg. Loss: 0.8628, Accuracy: 74.88%\n",
      "Epoch 7 Summary -> Avg. Loss: 0.8567, Accuracy: 74.95%\n",
      "Epoch 8 Summary -> Avg. Loss: 0.8511, Accuracy: 74.86%\n",
      "Epoch 9 Summary -> Avg. Loss: 0.8496, Accuracy: 74.61%\n",
      "Epoch 10 Summary -> Avg. Loss: 0.8379, Accuracy: 75.28%\n",
      "Epoch 11 Summary -> Avg. Loss: 0.8484, Accuracy: 74.57%\n",
      "Epoch 12 Summary -> Avg. Loss: 0.8487, Accuracy: 73.98%\n",
      "Epoch 13 Summary -> Avg. Loss: 0.8416, Accuracy: 74.65%\n",
      "Epoch 14 Summary -> Avg. Loss: 0.8375, Accuracy: 74.55%\n",
      "Epoch 15 Summary -> Avg. Loss: 0.8372, Accuracy: 74.42%\n",
      "Epoch 16 Summary -> Avg. Loss: 0.8362, Accuracy: 73.71%\n",
      "Epoch 17 Summary -> Avg. Loss: 0.8415, Accuracy: 74.55%\n",
      "Epoch 18 Summary -> Avg. Loss: 0.8328, Accuracy: 73.96%\n",
      "Epoch 19 Summary -> Avg. Loss: 0.8330, Accuracy: 74.64%\n",
      "Epoch 20 Summary -> Avg. Loss: 0.8468, Accuracy: 73.91%\n",
      "Epoch 21 Summary -> Avg. Loss: 0.8367, Accuracy: 74.56%\n",
      "Epoch 22 Summary -> Avg. Loss: 0.8191, Accuracy: 74.81%\n",
      "Epoch 23 Summary -> Avg. Loss: 0.8208, Accuracy: 74.53%\n",
      "Epoch 24 Summary -> Avg. Loss: 0.8103, Accuracy: 74.72%\n",
      "Epoch 25 Summary -> Avg. Loss: 0.8085, Accuracy: 74.54%\n",
      "Epoch 26 Summary -> Avg. Loss: 0.8088, Accuracy: 74.93%\n",
      "Epoch 27 Summary -> Avg. Loss: 0.8006, Accuracy: 74.98%\n",
      "Epoch 28 Summary -> Avg. Loss: 0.8125, Accuracy: 74.76%\n",
      "Epoch 29 Summary -> Avg. Loss: 0.8140, Accuracy: 74.54%\n",
      "Epoch 30 Summary -> Avg. Loss: 0.8199, Accuracy: 74.07%\n",
      "Epoch 31 Summary -> Avg. Loss: 0.8202, Accuracy: 74.18%\n",
      "Epoch 32 Summary -> Avg. Loss: 0.8330, Accuracy: 74.40%\n",
      "Epoch 33 Summary -> Avg. Loss: 0.8533, Accuracy: 73.75%\n",
      "Epoch 34 Summary -> Avg. Loss: 0.8624, Accuracy: 73.45%\n",
      "Epoch 35 Summary -> Avg. Loss: 0.8463, Accuracy: 74.24%\n",
      "Epoch 36 Summary -> Avg. Loss: 0.8536, Accuracy: 74.24%\n",
      "Epoch 37 Summary -> Avg. Loss: 0.8663, Accuracy: 73.70%\n",
      "Epoch 38 Summary -> Avg. Loss: 0.8658, Accuracy: 73.76%\n",
      "Epoch 39 Summary -> Avg. Loss: 0.8678, Accuracy: 73.22%\n",
      "Epoch 40 Summary -> Avg. Loss: 0.8493, Accuracy: 74.24%\n",
      "Epoch 41 Summary -> Avg. Loss: 0.8493, Accuracy: 74.11%\n",
      "Epoch 42 Summary -> Avg. Loss: 0.8388, Accuracy: 73.45%\n",
      "Epoch 43 Summary -> Avg. Loss: 0.8365, Accuracy: 74.18%\n",
      "Epoch 44 Summary -> Avg. Loss: 0.8571, Accuracy: 73.92%\n",
      "Epoch 45 Summary -> Avg. Loss: 0.8836, Accuracy: 73.76%\n",
      "Epoch 46 Summary -> Avg. Loss: 0.8562, Accuracy: 75.74%\n",
      "Epoch 47 Summary -> Avg. Loss: 0.8620, Accuracy: 74.86%\n",
      "Epoch 48 Summary -> Avg. Loss: 0.8634, Accuracy: 75.70%\n",
      "Epoch 49 Summary -> Avg. Loss: 0.8547, Accuracy: 75.57%\n",
      "Epoch 50 Summary -> Avg. Loss: 0.8766, Accuracy: 73.64%\n",
      "Epoch 51 Summary -> Avg. Loss: 0.8675, Accuracy: 74.96%\n",
      "Epoch 52 Summary -> Avg. Loss: 0.8564, Accuracy: 75.43%\n",
      "Epoch 53 Summary -> Avg. Loss: 0.8645, Accuracy: 75.09%\n",
      "Epoch 54 Summary -> Avg. Loss: 0.8554, Accuracy: 74.94%\n",
      "Epoch 55 Summary -> Avg. Loss: 0.8578, Accuracy: 75.98%\n",
      "Epoch 56 Summary -> Avg. Loss: 0.8601, Accuracy: 75.11%\n",
      "Epoch 57 Summary -> Avg. Loss: 0.8489, Accuracy: 74.22%\n",
      "Epoch 58 Summary -> Avg. Loss: 0.8628, Accuracy: 74.31%\n",
      "Epoch 59 Summary -> Avg. Loss: 0.8419, Accuracy: 75.31%\n",
      "Epoch 60 Summary -> Avg. Loss: 0.8568, Accuracy: 74.65%\n",
      "\n",
      "Total Train Time: 0h 25m 49s\n",
      "Evaluating model: RNN_Uni_dot...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating (RNN_Uni_dot):   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= RNN_Uni_dot =================\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Flare     0.9819    0.7497    0.8502      1878\n",
      "     C-Class     0.2374    0.7190    0.3570       210\n",
      "     M-Class     0.2623    0.4103    0.3200        39\n",
      "     X-Class     0.0000    0.0000    0.0000         4\n",
      "\n",
      "    accuracy                         0.7391      2131\n",
      "   macro avg     0.3704    0.4698    0.3818      2131\n",
      "weighted avg     0.8935    0.7391    0.7903      2131\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix:\n",
      " [[0.74973376 0.24547391 0.00479233 0.        ]\n",
      " [0.11904762 0.71904762 0.16190476 0.        ]\n",
      " [0.02564103 0.56410256 0.41025641 0.        ]\n",
      " [0.         0.5        0.5        0.        ]]\n",
      "\n",
      "Key Metrics Summary:\n",
      "  balanced_accuracy   : 0.4698\n",
      "  roc_auc_weighted    : 0.8977\n",
      "  mcc                 : 0.3718\n",
      "  f1_macro            : 0.3818\n",
      "  f1_weighted         : 0.7903\n",
      "RNN_Uni_dot.zip saved at /kaggle/working/RNN_Uni_dot.zip | Size: 0.18 MB\n",
      "\n",
      "============================== Experiment 4/12: RNN_Bi_dot ==============================\n",
      "Using 2 GPUs via DataParallel!\n",
      "Training model: RNN_Bi_dot for 60 epochs...\n",
      "Starting training for 60 epochs on cuda.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca388962e034c4cadb6499edc293e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/60 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Summary -> Avg. Loss: 0.9333, Accuracy: 74.19%\n",
      "Epoch 2 Summary -> Avg. Loss: 0.9276, Accuracy: 73.49%\n",
      "Epoch 3 Summary -> Avg. Loss: 0.9184, Accuracy: 73.35%\n",
      "Epoch 4 Summary -> Avg. Loss: 0.8956, Accuracy: 74.51%\n",
      "Epoch 5 Summary -> Avg. Loss: 0.8792, Accuracy: 74.67%\n",
      "Epoch 6 Summary -> Avg. Loss: 0.8675, Accuracy: 75.07%\n",
      "Epoch 7 Summary -> Avg. Loss: 0.8509, Accuracy: 75.08%\n",
      "Epoch 8 Summary -> Avg. Loss: 0.8656, Accuracy: 74.86%\n",
      "Epoch 9 Summary -> Avg. Loss: 0.8487, Accuracy: 75.09%\n",
      "Epoch 10 Summary -> Avg. Loss: 0.8367, Accuracy: 75.40%\n",
      "Epoch 11 Summary -> Avg. Loss: 0.8318, Accuracy: 75.97%\n",
      "Epoch 12 Summary -> Avg. Loss: 0.8230, Accuracy: 75.68%\n",
      "Epoch 13 Summary -> Avg. Loss: 0.8183, Accuracy: 75.75%\n",
      "Epoch 14 Summary -> Avg. Loss: 0.8123, Accuracy: 75.80%\n",
      "Epoch 15 Summary -> Avg. Loss: 0.8076, Accuracy: 75.71%\n",
      "Epoch 16 Summary -> Avg. Loss: 0.8035, Accuracy: 76.19%\n",
      "Epoch 17 Summary -> Avg. Loss: 0.7920, Accuracy: 76.25%\n",
      "Epoch 18 Summary -> Avg. Loss: 0.7946, Accuracy: 76.15%\n",
      "Epoch 19 Summary -> Avg. Loss: 0.8206, Accuracy: 75.38%\n",
      "Epoch 20 Summary -> Avg. Loss: 0.8000, Accuracy: 75.79%\n",
      "Epoch 21 Summary -> Avg. Loss: 0.7759, Accuracy: 76.55%\n",
      "Epoch 22 Summary -> Avg. Loss: 0.7997, Accuracy: 76.13%\n",
      "Epoch 23 Summary -> Avg. Loss: 0.7949, Accuracy: 76.06%\n",
      "Epoch 24 Summary -> Avg. Loss: 0.7756, Accuracy: 76.40%\n",
      "Epoch 25 Summary -> Avg. Loss: 0.7760, Accuracy: 76.24%\n",
      "Epoch 26 Summary -> Avg. Loss: 0.7644, Accuracy: 76.56%\n",
      "Epoch 27 Summary -> Avg. Loss: 0.7548, Accuracy: 76.75%\n",
      "Epoch 28 Summary -> Avg. Loss: 0.7577, Accuracy: 76.45%\n",
      "Epoch 29 Summary -> Avg. Loss: 0.7515, Accuracy: 76.69%\n",
      "Epoch 30 Summary -> Avg. Loss: 0.7674, Accuracy: 76.51%\n",
      "Epoch 31 Summary -> Avg. Loss: 0.7586, Accuracy: 76.61%\n",
      "Epoch 32 Summary -> Avg. Loss: 0.7443, Accuracy: 76.80%\n",
      "Epoch 33 Summary -> Avg. Loss: 0.7434, Accuracy: 76.66%\n",
      "Epoch 34 Summary -> Avg. Loss: 0.7454, Accuracy: 76.44%\n",
      "Epoch 35 Summary -> Avg. Loss: 0.7444, Accuracy: 77.08%\n",
      "Epoch 36 Summary -> Avg. Loss: 0.7472, Accuracy: 76.46%\n",
      "Epoch 37 Summary -> Avg. Loss: 0.7580, Accuracy: 76.54%\n",
      "Epoch 38 Summary -> Avg. Loss: 0.7551, Accuracy: 76.62%\n",
      "Epoch 39 Summary -> Avg. Loss: 0.7526, Accuracy: 76.82%\n",
      "Epoch 40 Summary -> Avg. Loss: 0.7534, Accuracy: 76.49%\n",
      "Epoch 41 Summary -> Avg. Loss: 0.7352, Accuracy: 76.83%\n",
      "Epoch 42 Summary -> Avg. Loss: 0.7508, Accuracy: 76.44%\n",
      "Epoch 43 Summary -> Avg. Loss: 0.7431, Accuracy: 77.02%\n",
      "Epoch 44 Summary -> Avg. Loss: 0.7404, Accuracy: 76.90%\n",
      "Epoch 45 Summary -> Avg. Loss: 0.7532, Accuracy: 76.42%\n",
      "Epoch 46 Summary -> Avg. Loss: 0.7368, Accuracy: 76.90%\n",
      "Epoch 47 Summary -> Avg. Loss: 0.7269, Accuracy: 76.90%\n",
      "Epoch 48 Summary -> Avg. Loss: 0.7294, Accuracy: 76.91%\n",
      "Epoch 49 Summary -> Avg. Loss: 0.7336, Accuracy: 76.89%\n",
      "Epoch 50 Summary -> Avg. Loss: 0.7469, Accuracy: 76.76%\n",
      "Epoch 51 Summary -> Avg. Loss: 0.7159, Accuracy: 76.71%\n",
      "Epoch 52 Summary -> Avg. Loss: 0.7317, Accuracy: 76.83%\n",
      "Epoch 53 Summary -> Avg. Loss: 0.7326, Accuracy: 77.01%\n",
      "Epoch 54 Summary -> Avg. Loss: 0.7235, Accuracy: 77.13%\n",
      "Epoch 55 Summary -> Avg. Loss: 0.7252, Accuracy: 76.88%\n",
      "Epoch 56 Summary -> Avg. Loss: 0.7336, Accuracy: 77.01%\n",
      "Epoch 57 Summary -> Avg. Loss: 0.7338, Accuracy: 76.74%\n",
      "Epoch 58 Summary -> Avg. Loss: 0.7391, Accuracy: 76.66%\n",
      "Epoch 59 Summary -> Avg. Loss: 0.7292, Accuracy: 77.01%\n",
      "Epoch 60 Summary -> Avg. Loss: 0.7286, Accuracy: 76.73%\n",
      "\n",
      "Total Train Time: 0h 30m 14s\n",
      "Evaluating model: RNN_Bi_dot...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating (RNN_Bi_dot):   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= RNN_Bi_dot =================\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Flare     0.9789    0.8142    0.8890      1878\n",
      "     C-Class     0.2813    0.5238    0.3661       210\n",
      "     M-Class     0.1720    0.6923    0.2755        39\n",
      "     X-Class     0.1905    1.0000    0.3200         4\n",
      "\n",
      "    accuracy                         0.7837      2131\n",
      "   macro avg     0.4057    0.7576    0.4626      2131\n",
      "weighted avg     0.8939    0.7837    0.8251      2131\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix:\n",
      " [[0.814164   0.14536741 0.03620873 0.00425985]\n",
      " [0.14761905 0.52380952 0.2952381  0.03333333]\n",
      " [0.05128205 0.20512821 0.69230769 0.05128205]\n",
      " [0.         0.         0.         1.        ]]\n",
      "\n",
      "Key Metrics Summary:\n",
      "  balanced_accuracy   : 0.7576\n",
      "  roc_auc_weighted    : 0.9120\n",
      "  mcc                 : 0.3934\n",
      "  f1_macro            : 0.4626\n",
      "  f1_weighted         : 0.8251\n",
      "RNN_Bi_dot.zip saved at /kaggle/working/RNN_Bi_dot.zip | Size: 0.48 MB\n",
      "\n",
      "============================== Experiment 5/12: RNN_Uni_concat ==============================\n",
      "Using 2 GPUs via DataParallel!\n",
      "Training model: RNN_Uni_concat for 60 epochs...\n",
      "Starting training for 60 epochs on cuda.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dbcd84016674b12bddf5c4d92799e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/60 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Summary -> Avg. Loss: 0.8559, Accuracy: 75.20%\n",
      "Epoch 2 Summary -> Avg. Loss: 0.8465, Accuracy: 75.15%\n",
      "Epoch 3 Summary -> Avg. Loss: 0.8405, Accuracy: 75.38%\n",
      "Epoch 4 Summary -> Avg. Loss: 0.8258, Accuracy: 75.09%\n",
      "Epoch 5 Summary -> Avg. Loss: 0.8030, Accuracy: 75.59%\n",
      "Epoch 6 Summary -> Avg. Loss: 0.7921, Accuracy: 75.82%\n",
      "Epoch 7 Summary -> Avg. Loss: 0.7868, Accuracy: 76.08%\n",
      "Epoch 8 Summary -> Avg. Loss: 0.7669, Accuracy: 76.52%\n",
      "Epoch 9 Summary -> Avg. Loss: 0.7628, Accuracy: 76.50%\n",
      "Epoch 10 Summary -> Avg. Loss: 0.7570, Accuracy: 76.60%\n",
      "Epoch 11 Summary -> Avg. Loss: 0.7539, Accuracy: 76.81%\n",
      "Epoch 12 Summary -> Avg. Loss: 0.7445, Accuracy: 76.92%\n",
      "Epoch 13 Summary -> Avg. Loss: 0.7353, Accuracy: 76.75%\n",
      "Epoch 14 Summary -> Avg. Loss: 0.7250, Accuracy: 77.03%\n",
      "Epoch 15 Summary -> Avg. Loss: 0.7164, Accuracy: 77.02%\n",
      "Epoch 16 Summary -> Avg. Loss: 0.7191, Accuracy: 76.74%\n",
      "Epoch 17 Summary -> Avg. Loss: 0.7079, Accuracy: 77.05%\n",
      "Epoch 18 Summary -> Avg. Loss: 0.7126, Accuracy: 77.12%\n",
      "Epoch 19 Summary -> Avg. Loss: 0.7019, Accuracy: 77.09%\n",
      "Epoch 20 Summary -> Avg. Loss: 0.7029, Accuracy: 77.30%\n",
      "Epoch 21 Summary -> Avg. Loss: 0.7146, Accuracy: 77.02%\n",
      "Epoch 22 Summary -> Avg. Loss: 0.7032, Accuracy: 77.30%\n",
      "Epoch 23 Summary -> Avg. Loss: 0.7038, Accuracy: 77.11%\n",
      "Epoch 24 Summary -> Avg. Loss: 0.6897, Accuracy: 77.57%\n",
      "Epoch 25 Summary -> Avg. Loss: 0.6801, Accuracy: 77.45%\n",
      "Epoch 26 Summary -> Avg. Loss: 0.7025, Accuracy: 77.30%\n",
      "Epoch 27 Summary -> Avg. Loss: 0.6782, Accuracy: 77.45%\n",
      "Epoch 28 Summary -> Avg. Loss: 0.6667, Accuracy: 77.93%\n",
      "Epoch 29 Summary -> Avg. Loss: 0.6672, Accuracy: 77.83%\n",
      "Epoch 30 Summary -> Avg. Loss: 0.6650, Accuracy: 77.96%\n",
      "Epoch 31 Summary -> Avg. Loss: 0.6740, Accuracy: 78.03%\n",
      "Epoch 32 Summary -> Avg. Loss: 0.6665, Accuracy: 77.89%\n",
      "Epoch 33 Summary -> Avg. Loss: 0.6667, Accuracy: 77.83%\n",
      "Epoch 34 Summary -> Avg. Loss: 0.6692, Accuracy: 77.89%\n",
      "Epoch 35 Summary -> Avg. Loss: 0.6669, Accuracy: 77.55%\n",
      "Epoch 36 Summary -> Avg. Loss: 0.6606, Accuracy: 77.87%\n",
      "Epoch 37 Summary -> Avg. Loss: 0.6807, Accuracy: 77.60%\n",
      "Epoch 38 Summary -> Avg. Loss: 0.6851, Accuracy: 77.87%\n",
      "Epoch 39 Summary -> Avg. Loss: 0.6741, Accuracy: 77.60%\n",
      "Epoch 40 Summary -> Avg. Loss: 0.6742, Accuracy: 78.31%\n",
      "Epoch 41 Summary -> Avg. Loss: 0.6550, Accuracy: 77.81%\n",
      "Epoch 42 Summary -> Avg. Loss: 0.6517, Accuracy: 78.05%\n",
      "Epoch 43 Summary -> Avg. Loss: 0.6563, Accuracy: 77.60%\n",
      "Epoch 44 Summary -> Avg. Loss: 0.6451, Accuracy: 77.30%\n",
      "Epoch 45 Summary -> Avg. Loss: 0.6361, Accuracy: 77.72%\n",
      "Epoch 46 Summary -> Avg. Loss: 0.6425, Accuracy: 77.95%\n",
      "Epoch 47 Summary -> Avg. Loss: 0.6520, Accuracy: 77.76%\n",
      "Epoch 48 Summary -> Avg. Loss: 0.6333, Accuracy: 78.45%\n",
      "Epoch 49 Summary -> Avg. Loss: 0.6378, Accuracy: 78.24%\n",
      "Epoch 50 Summary -> Avg. Loss: 0.6382, Accuracy: 78.13%\n",
      "Epoch 51 Summary -> Avg. Loss: 0.6484, Accuracy: 77.59%\n",
      "Epoch 52 Summary -> Avg. Loss: 0.6457, Accuracy: 77.94%\n",
      "Epoch 53 Summary -> Avg. Loss: 0.6421, Accuracy: 77.64%\n",
      "Epoch 54 Summary -> Avg. Loss: 0.6423, Accuracy: 77.60%\n",
      "Epoch 55 Summary -> Avg. Loss: 0.6232, Accuracy: 77.93%\n",
      "Epoch 56 Summary -> Avg. Loss: 0.6389, Accuracy: 77.97%\n",
      "Epoch 57 Summary -> Avg. Loss: 0.7849, Accuracy: 76.63%\n",
      "Epoch 58 Summary -> Avg. Loss: 0.7349, Accuracy: 76.97%\n",
      "Epoch 59 Summary -> Avg. Loss: 0.7163, Accuracy: 77.26%\n",
      "Epoch 60 Summary -> Avg. Loss: 0.7029, Accuracy: 77.28%\n",
      "\n",
      "Total Train Time: 0h 25m 52s\n",
      "Evaluating model: RNN_Uni_concat...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating (RNN_Uni_concat):   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= RNN_Uni_concat =================\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Flare     0.9818    0.7764    0.8671      1878\n",
      "     C-Class     0.2625    0.6524    0.3743       210\n",
      "     M-Class     0.2376    0.6154    0.3429        39\n",
      "     X-Class     0.1304    0.7500    0.2222         4\n",
      "\n",
      "    accuracy                         0.7611      2131\n",
      "   macro avg     0.4031    0.6985    0.4516      2131\n",
      "weighted avg     0.8957    0.7611    0.8077      2131\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix:\n",
      " [[0.77635783 0.19808307 0.02183174 0.00372737]\n",
      " [0.12380952 0.65238095 0.17142857 0.05238095]\n",
      " [0.02564103 0.30769231 0.61538462 0.05128205]\n",
      " [0.         0.25       0.         0.75      ]]\n",
      "\n",
      "Key Metrics Summary:\n",
      "  balanced_accuracy   : 0.6985\n",
      "  roc_auc_weighted    : 0.9079\n",
      "  mcc                 : 0.3929\n",
      "  f1_macro            : 0.4516\n",
      "  f1_weighted         : 0.8077\n",
      "RNN_Uni_concat.zip saved at /kaggle/working/RNN_Uni_concat.zip | Size: 0.18 MB\n",
      "\n",
      "============================== Experiment 6/12: RNN_Bi_concat ==============================\n",
      "Using 2 GPUs via DataParallel!\n",
      "Training model: RNN_Bi_concat for 60 epochs...\n",
      "Starting training for 60 epochs on cuda.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77ec33c548047ccb4baad7d4b56c1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/60 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Summary -> Avg. Loss: 0.8564, Accuracy: 75.69%\n",
      "Epoch 2 Summary -> Avg. Loss: 0.8567, Accuracy: 75.33%\n",
      "Epoch 3 Summary -> Avg. Loss: 0.8542, Accuracy: 75.41%\n",
      "Epoch 4 Summary -> Avg. Loss: 0.8429, Accuracy: 75.45%\n",
      "Epoch 5 Summary -> Avg. Loss: 0.8516, Accuracy: 75.25%\n",
      "Epoch 6 Summary -> Avg. Loss: 0.8697, Accuracy: 75.25%\n",
      "Epoch 7 Summary -> Avg. Loss: 0.8505, Accuracy: 75.92%\n",
      "Epoch 8 Summary -> Avg. Loss: 0.8397, Accuracy: 75.65%\n",
      "Epoch 9 Summary -> Avg. Loss: 0.8229, Accuracy: 76.07%\n",
      "Epoch 10 Summary -> Avg. Loss: 0.8372, Accuracy: 75.39%\n",
      "Epoch 11 Summary -> Avg. Loss: 0.8208, Accuracy: 75.87%\n",
      "Epoch 12 Summary -> Avg. Loss: 0.8306, Accuracy: 75.84%\n",
      "Epoch 13 Summary -> Avg. Loss: 0.8228, Accuracy: 76.27%\n",
      "Epoch 14 Summary -> Avg. Loss: 0.8200, Accuracy: 75.95%\n",
      "Epoch 15 Summary -> Avg. Loss: 0.8210, Accuracy: 75.99%\n",
      "Epoch 16 Summary -> Avg. Loss: 0.8102, Accuracy: 76.02%\n",
      "Epoch 17 Summary -> Avg. Loss: 0.8018, Accuracy: 76.36%\n",
      "Epoch 18 Summary -> Avg. Loss: 0.8126, Accuracy: 76.24%\n",
      "Epoch 19 Summary -> Avg. Loss: 0.7965, Accuracy: 76.36%\n",
      "Epoch 20 Summary -> Avg. Loss: 0.7836, Accuracy: 76.84%\n",
      "Epoch 21 Summary -> Avg. Loss: 0.7919, Accuracy: 76.54%\n",
      "Epoch 22 Summary -> Avg. Loss: 0.7769, Accuracy: 76.66%\n",
      "Epoch 23 Summary -> Avg. Loss: 0.7788, Accuracy: 76.67%\n",
      "Epoch 24 Summary -> Avg. Loss: 0.7830, Accuracy: 76.52%\n",
      "Epoch 25 Summary -> Avg. Loss: 0.7765, Accuracy: 76.68%\n",
      "Epoch 26 Summary -> Avg. Loss: 0.7811, Accuracy: 76.09%\n",
      "Epoch 27 Summary -> Avg. Loss: 0.7694, Accuracy: 76.57%\n",
      "Epoch 28 Summary -> Avg. Loss: 0.7853, Accuracy: 76.42%\n",
      "Epoch 29 Summary -> Avg. Loss: 0.7799, Accuracy: 76.37%\n",
      "Epoch 30 Summary -> Avg. Loss: 0.7892, Accuracy: 76.77%\n",
      "Epoch 31 Summary -> Avg. Loss: 0.7797, Accuracy: 76.69%\n",
      "Epoch 32 Summary -> Avg. Loss: 0.7778, Accuracy: 76.54%\n",
      "Epoch 33 Summary -> Avg. Loss: 0.7815, Accuracy: 76.58%\n",
      "Epoch 34 Summary -> Avg. Loss: 0.7712, Accuracy: 76.99%\n",
      "Epoch 35 Summary -> Avg. Loss: 0.7728, Accuracy: 76.69%\n",
      "Epoch 36 Summary -> Avg. Loss: 0.7687, Accuracy: 76.62%\n",
      "Epoch 37 Summary -> Avg. Loss: 0.7887, Accuracy: 76.56%\n",
      "Epoch 38 Summary -> Avg. Loss: 0.8164, Accuracy: 76.41%\n",
      "Epoch 39 Summary -> Avg. Loss: 0.7986, Accuracy: 76.29%\n",
      "Epoch 40 Summary -> Avg. Loss: 0.7865, Accuracy: 76.40%\n",
      "Epoch 41 Summary -> Avg. Loss: 0.7729, Accuracy: 76.36%\n",
      "Epoch 42 Summary -> Avg. Loss: 0.7673, Accuracy: 76.60%\n",
      "Epoch 43 Summary -> Avg. Loss: 0.7651, Accuracy: 76.88%\n",
      "Epoch 44 Summary -> Avg. Loss: 0.7768, Accuracy: 76.49%\n",
      "Epoch 45 Summary -> Avg. Loss: 0.7704, Accuracy: 76.24%\n",
      "Epoch 46 Summary -> Avg. Loss: 0.7627, Accuracy: 76.15%\n",
      "Epoch 47 Summary -> Avg. Loss: 0.7569, Accuracy: 76.57%\n",
      "Epoch 48 Summary -> Avg. Loss: 0.7494, Accuracy: 76.75%\n",
      "Epoch 49 Summary -> Avg. Loss: 0.7474, Accuracy: 76.97%\n",
      "Epoch 50 Summary -> Avg. Loss: 0.7653, Accuracy: 76.66%\n",
      "Epoch 51 Summary -> Avg. Loss: 0.7539, Accuracy: 76.98%\n",
      "Epoch 52 Summary -> Avg. Loss: 0.7764, Accuracy: 76.90%\n",
      "Epoch 53 Summary -> Avg. Loss: 0.7770, Accuracy: 76.24%\n",
      "Epoch 54 Summary -> Avg. Loss: 0.7582, Accuracy: 76.77%\n",
      "Epoch 55 Summary -> Avg. Loss: 0.7655, Accuracy: 76.56%\n",
      "Epoch 56 Summary -> Avg. Loss: 0.7609, Accuracy: 76.55%\n",
      "Epoch 57 Summary -> Avg. Loss: 0.7559, Accuracy: 76.62%\n",
      "Epoch 58 Summary -> Avg. Loss: 0.7664, Accuracy: 77.05%\n",
      "Epoch 59 Summary -> Avg. Loss: 0.7552, Accuracy: 76.81%\n",
      "Epoch 60 Summary -> Avg. Loss: 0.7545, Accuracy: 76.72%\n",
      "\n",
      "Total Train Time: 0h 28m 45s\n",
      "Evaluating model: RNN_Bi_concat...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating (RNN_Bi_concat):   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= RNN_Bi_concat =================\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Flare     0.9905    0.7194    0.8334      1878\n",
      "     C-Class     0.2371    0.7238    0.3572       210\n",
      "     M-Class     0.1966    0.5897    0.2949        39\n",
      "     X-Class     0.2222    0.5000    0.3077         4\n",
      "\n",
      "    accuracy                         0.7170      2131\n",
      "   macro avg     0.4116    0.6332    0.4483      2131\n",
      "weighted avg     0.9003    0.7170    0.7757      2131\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix:\n",
      " [[0.71938232 0.25239617 0.02822151 0.        ]\n",
      " [0.05714286 0.72380952 0.19047619 0.02857143]\n",
      " [0.02564103 0.35897436 0.58974359 0.02564103]\n",
      " [0.         0.25       0.25       0.5       ]]\n",
      "\n",
      "Key Metrics Summary:\n",
      "  balanced_accuracy   : 0.6332\n",
      "  roc_auc_weighted    : 0.9037\n",
      "  mcc                 : 0.3757\n",
      "  f1_macro            : 0.4483\n",
      "  f1_weighted         : 0.7757\n",
      "RNN_Bi_concat.zip saved at /kaggle/working/RNN_Bi_concat.zip | Size: 0.48 MB\n",
      "\n",
      "============================== Experiment 7/12: LSTM_Uni_NoAtt ==============================\n",
      "Using 2 GPUs via DataParallel!\n",
      "Training model: LSTM_Uni_NoAtt for 60 epochs...\n",
      "Starting training for 60 epochs on cuda.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1964c28371654710aff21de0457268ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/60 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Summary -> Avg. Loss: 0.8527, Accuracy: 75.37%\n",
      "Epoch 2 Summary -> Avg. Loss: 0.7969, Accuracy: 76.02%\n",
      "Epoch 3 Summary -> Avg. Loss: 0.7723, Accuracy: 76.51%\n",
      "Epoch 4 Summary -> Avg. Loss: 0.7622, Accuracy: 76.85%\n",
      "Epoch 5 Summary -> Avg. Loss: 0.7446, Accuracy: 76.33%\n",
      "Epoch 6 Summary -> Avg. Loss: 0.7541, Accuracy: 76.51%\n",
      "Epoch 7 Summary -> Avg. Loss: 0.7303, Accuracy: 77.18%\n",
      "Epoch 8 Summary -> Avg. Loss: 0.7141, Accuracy: 77.39%\n",
      "Epoch 9 Summary -> Avg. Loss: 0.7006, Accuracy: 77.32%\n",
      "Epoch 10 Summary -> Avg. Loss: 0.7044, Accuracy: 77.32%\n",
      "Epoch 11 Summary -> Avg. Loss: 0.7051, Accuracy: 77.52%\n",
      "Epoch 12 Summary -> Avg. Loss: 0.6952, Accuracy: 77.41%\n",
      "Epoch 13 Summary -> Avg. Loss: 0.6916, Accuracy: 77.22%\n",
      "Epoch 14 Summary -> Avg. Loss: 0.7108, Accuracy: 77.62%\n",
      "Epoch 15 Summary -> Avg. Loss: 0.6792, Accuracy: 77.68%\n",
      "Epoch 16 Summary -> Avg. Loss: 0.6716, Accuracy: 77.70%\n",
      "Epoch 17 Summary -> Avg. Loss: 0.6599, Accuracy: 78.03%\n",
      "Epoch 18 Summary -> Avg. Loss: 0.6496, Accuracy: 78.18%\n",
      "Epoch 19 Summary -> Avg. Loss: 0.6737, Accuracy: 77.28%\n",
      "Epoch 20 Summary -> Avg. Loss: 0.6556, Accuracy: 77.67%\n",
      "Epoch 21 Summary -> Avg. Loss: 0.6361, Accuracy: 78.03%\n",
      "Epoch 22 Summary -> Avg. Loss: 0.6378, Accuracy: 77.58%\n",
      "Epoch 23 Summary -> Avg. Loss: 0.6270, Accuracy: 78.02%\n",
      "Epoch 24 Summary -> Avg. Loss: 0.5994, Accuracy: 78.34%\n",
      "Epoch 25 Summary -> Avg. Loss: 0.5936, Accuracy: 78.65%\n",
      "Epoch 26 Summary -> Avg. Loss: 0.6033, Accuracy: 78.69%\n",
      "Epoch 27 Summary -> Avg. Loss: 0.6075, Accuracy: 78.32%\n",
      "Epoch 28 Summary -> Avg. Loss: 0.6295, Accuracy: 78.52%\n",
      "Epoch 29 Summary -> Avg. Loss: 0.6232, Accuracy: 78.46%\n",
      "Epoch 30 Summary -> Avg. Loss: 0.6126, Accuracy: 78.29%\n",
      "Epoch 31 Summary -> Avg. Loss: 0.6294, Accuracy: 78.13%\n",
      "Epoch 32 Summary -> Avg. Loss: 0.6149, Accuracy: 78.38%\n",
      "Epoch 33 Summary -> Avg. Loss: 0.6143, Accuracy: 78.18%\n",
      "Epoch 34 Summary -> Avg. Loss: 0.6053, Accuracy: 78.52%\n",
      "Epoch 35 Summary -> Avg. Loss: 0.5821, Accuracy: 78.91%\n",
      "Epoch 36 Summary -> Avg. Loss: 0.6037, Accuracy: 78.62%\n",
      "Epoch 37 Summary -> Avg. Loss: 0.5655, Accuracy: 79.20%\n",
      "Epoch 38 Summary -> Avg. Loss: 0.5504, Accuracy: 79.24%\n",
      "Epoch 39 Summary -> Avg. Loss: 0.5821, Accuracy: 79.06%\n",
      "Epoch 40 Summary -> Avg. Loss: 0.5548, Accuracy: 79.01%\n",
      "Epoch 41 Summary -> Avg. Loss: 0.5442, Accuracy: 78.87%\n",
      "Epoch 42 Summary -> Avg. Loss: 0.5515, Accuracy: 78.96%\n",
      "Epoch 43 Summary -> Avg. Loss: 0.5240, Accuracy: 79.62%\n",
      "Epoch 44 Summary -> Avg. Loss: 0.5490, Accuracy: 79.32%\n",
      "Epoch 45 Summary -> Avg. Loss: 0.5770, Accuracy: 78.87%\n",
      "Epoch 46 Summary -> Avg. Loss: 0.5314, Accuracy: 79.35%\n",
      "Epoch 47 Summary -> Avg. Loss: 0.5236, Accuracy: 79.73%\n",
      "Epoch 48 Summary -> Avg. Loss: 0.5029, Accuracy: 80.09%\n",
      "Epoch 49 Summary -> Avg. Loss: 0.4915, Accuracy: 80.53%\n",
      "Epoch 50 Summary -> Avg. Loss: 0.4763, Accuracy: 80.36%\n",
      "Epoch 51 Summary -> Avg. Loss: 0.4835, Accuracy: 80.38%\n",
      "Epoch 52 Summary -> Avg. Loss: 0.4849, Accuracy: 80.54%\n",
      "Epoch 53 Summary -> Avg. Loss: 0.4671, Accuracy: 80.83%\n",
      "Epoch 54 Summary -> Avg. Loss: 0.4406, Accuracy: 81.40%\n",
      "Epoch 55 Summary -> Avg. Loss: 0.4633, Accuracy: 80.99%\n",
      "Epoch 56 Summary -> Avg. Loss: 0.4616, Accuracy: 81.03%\n",
      "Epoch 57 Summary -> Avg. Loss: 0.4354, Accuracy: 81.12%\n",
      "Epoch 58 Summary -> Avg. Loss: 0.5126, Accuracy: 80.32%\n",
      "Epoch 59 Summary -> Avg. Loss: 0.4723, Accuracy: 80.87%\n",
      "Epoch 60 Summary -> Avg. Loss: 0.5167, Accuracy: 80.35%\n",
      "\n",
      "Total Train Time: 0h 31m 9s\n",
      "Evaluating model: LSTM_Uni_NoAtt...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating (LSTM_Uni_NoAtt):   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= LSTM_Uni_NoAtt =================\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Flare     0.9855    0.7945    0.8797      1878\n",
      "     C-Class     0.3163    0.7667    0.4478       210\n",
      "     M-Class     0.3100    0.7949    0.4460        39\n",
      "     X-Class     0.3750    0.7500    0.5000         4\n",
      "\n",
      "    accuracy                         0.7916      2131\n",
      "   macro avg     0.4967    0.7765    0.5684      2131\n",
      "weighted avg     0.9060    0.7916    0.8285      2131\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix:\n",
      " [[7.94462194e-01 1.81043663e-01 2.39616613e-02 5.32481363e-04]\n",
      " [1.04761905e-01 7.66666667e-01 1.14285714e-01 1.42857143e-02]\n",
      " [0.00000000e+00 1.79487179e-01 7.94871795e-01 2.56410256e-02]\n",
      " [0.00000000e+00 2.50000000e-01 0.00000000e+00 7.50000000e-01]]\n",
      "\n",
      "Key Metrics Summary:\n",
      "  balanced_accuracy   : 0.7765\n",
      "  roc_auc_weighted    : 0.9233\n",
      "  mcc                 : 0.4628\n",
      "  f1_macro            : 0.5684\n",
      "  f1_weighted         : 0.8285\n",
      "LSTM_Uni_NoAtt.zip saved at /kaggle/working/LSTM_Uni_NoAtt.zip | Size: 0.73 MB\n",
      "\n",
      "============================== Experiment 8/12: LSTM_Bi_NoAtt ==============================\n",
      "Using 2 GPUs via DataParallel!\n",
      "Training model: LSTM_Bi_NoAtt for 60 epochs...\n",
      "Starting training for 60 epochs on cuda.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0cdfae83a74063ab1066c75c236a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/60 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Summary -> Avg. Loss: 0.8351, Accuracy: 75.30%\n",
      "Epoch 2 Summary -> Avg. Loss: 0.7886, Accuracy: 76.27%\n",
      "Epoch 3 Summary -> Avg. Loss: 0.7628, Accuracy: 76.27%\n",
      "Epoch 4 Summary -> Avg. Loss: 0.7455, Accuracy: 76.53%\n",
      "Epoch 5 Summary -> Avg. Loss: 0.7407, Accuracy: 77.02%\n",
      "Epoch 6 Summary -> Avg. Loss: 0.7168, Accuracy: 77.26%\n",
      "Epoch 7 Summary -> Avg. Loss: 0.7039, Accuracy: 77.22%\n",
      "Epoch 8 Summary -> Avg. Loss: 0.6945, Accuracy: 77.06%\n",
      "Epoch 9 Summary -> Avg. Loss: 0.6817, Accuracy: 77.41%\n",
      "Epoch 10 Summary -> Avg. Loss: 0.6675, Accuracy: 77.64%\n",
      "Epoch 11 Summary -> Avg. Loss: 0.6598, Accuracy: 77.67%\n",
      "Epoch 12 Summary -> Avg. Loss: 0.6445, Accuracy: 77.67%\n",
      "Epoch 13 Summary -> Avg. Loss: 0.6513, Accuracy: 78.18%\n",
      "Epoch 14 Summary -> Avg. Loss: 0.6399, Accuracy: 78.05%\n",
      "Epoch 15 Summary -> Avg. Loss: 0.6171, Accuracy: 78.52%\n",
      "Epoch 16 Summary -> Avg. Loss: 0.6225, Accuracy: 78.48%\n",
      "Epoch 17 Summary -> Avg. Loss: 0.5966, Accuracy: 78.77%\n",
      "Epoch 18 Summary -> Avg. Loss: 0.5927, Accuracy: 78.88%\n",
      "Epoch 19 Summary -> Avg. Loss: 0.6018, Accuracy: 78.71%\n",
      "Epoch 20 Summary -> Avg. Loss: 0.5980, Accuracy: 78.81%\n",
      "Epoch 21 Summary -> Avg. Loss: 0.5824, Accuracy: 79.06%\n",
      "Epoch 22 Summary -> Avg. Loss: 0.5634, Accuracy: 79.48%\n",
      "Epoch 23 Summary -> Avg. Loss: 0.5489, Accuracy: 79.60%\n",
      "Epoch 24 Summary -> Avg. Loss: 0.5560, Accuracy: 79.79%\n",
      "Epoch 25 Summary -> Avg. Loss: 0.5240, Accuracy: 80.25%\n",
      "Epoch 26 Summary -> Avg. Loss: 0.5064, Accuracy: 80.60%\n",
      "Epoch 27 Summary -> Avg. Loss: 0.5148, Accuracy: 80.66%\n",
      "Epoch 28 Summary -> Avg. Loss: 0.5446, Accuracy: 79.64%\n",
      "Epoch 29 Summary -> Avg. Loss: 0.5516, Accuracy: 79.41%\n",
      "Epoch 30 Summary -> Avg. Loss: 0.5309, Accuracy: 79.76%\n",
      "Epoch 31 Summary -> Avg. Loss: 0.5232, Accuracy: 79.92%\n",
      "Epoch 32 Summary -> Avg. Loss: 0.5342, Accuracy: 79.78%\n",
      "Epoch 33 Summary -> Avg. Loss: 0.5539, Accuracy: 79.77%\n",
      "Epoch 34 Summary -> Avg. Loss: 0.5025, Accuracy: 80.84%\n",
      "Epoch 35 Summary -> Avg. Loss: 0.4791, Accuracy: 80.68%\n",
      "Epoch 36 Summary -> Avg. Loss: 0.5137, Accuracy: 80.49%\n",
      "Epoch 37 Summary -> Avg. Loss: 0.5531, Accuracy: 80.24%\n",
      "Epoch 38 Summary -> Avg. Loss: 0.5487, Accuracy: 79.88%\n",
      "Epoch 39 Summary -> Avg. Loss: 0.6861, Accuracy: 78.13%\n",
      "Epoch 40 Summary -> Avg. Loss: 0.6291, Accuracy: 78.91%\n",
      "Epoch 41 Summary -> Avg. Loss: 0.6220, Accuracy: 79.02%\n",
      "Epoch 42 Summary -> Avg. Loss: 0.6144, Accuracy: 79.15%\n",
      "Epoch 43 Summary -> Avg. Loss: 0.6351, Accuracy: 78.85%\n",
      "Epoch 44 Summary -> Avg. Loss: 0.6490, Accuracy: 78.66%\n",
      "Epoch 45 Summary -> Avg. Loss: 0.6071, Accuracy: 79.28%\n",
      "Epoch 46 Summary -> Avg. Loss: 0.6038, Accuracy: 79.04%\n",
      "Epoch 47 Summary -> Avg. Loss: 0.6296, Accuracy: 78.55%\n",
      "Epoch 48 Summary -> Avg. Loss: 0.6177, Accuracy: 79.00%\n",
      "Epoch 49 Summary -> Avg. Loss: 0.5916, Accuracy: 79.13%\n",
      "Epoch 50 Summary -> Avg. Loss: 0.5886, Accuracy: 79.32%\n",
      "Epoch 51 Summary -> Avg. Loss: 0.5874, Accuracy: 79.28%\n",
      "Epoch 52 Summary -> Avg. Loss: 0.6055, Accuracy: 78.44%\n",
      "Epoch 53 Summary -> Avg. Loss: 0.6279, Accuracy: 78.37%\n",
      "Epoch 54 Summary -> Avg. Loss: 0.6115, Accuracy: 78.40%\n",
      "Epoch 55 Summary -> Avg. Loss: 0.5757, Accuracy: 79.06%\n",
      "Epoch 56 Summary -> Avg. Loss: 0.6098, Accuracy: 78.60%\n",
      "Epoch 57 Summary -> Avg. Loss: 0.5952, Accuracy: 78.94%\n",
      "Epoch 58 Summary -> Avg. Loss: 0.5952, Accuracy: 79.16%\n",
      "Epoch 59 Summary -> Avg. Loss: 0.5921, Accuracy: 78.66%\n",
      "Epoch 60 Summary -> Avg. Loss: 0.6253, Accuracy: 78.61%\n",
      "\n",
      "Total Train Time: 0h 59m 47s\n",
      "Evaluating model: LSTM_Bi_NoAtt...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating (LSTM_Bi_NoAtt):   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= LSTM_Bi_NoAtt =================\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Flare     0.9862    0.8003    0.8836      1878\n",
      "     C-Class     0.3042    0.6619    0.4168       210\n",
      "     M-Class     0.2080    0.6667    0.3171        39\n",
      "     X-Class     0.1600    1.0000    0.2759         4\n",
      "\n",
      "    accuracy                         0.7846      2131\n",
      "   macro avg     0.4146    0.7822    0.4733      2131\n",
      "weighted avg     0.9032    0.7846    0.8261      2131\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix:\n",
      " [[0.80031949 0.1656017  0.03088392 0.00319489]\n",
      " [0.1        0.66190476 0.1952381  0.04285714]\n",
      " [0.         0.17948718 0.66666667 0.15384615]\n",
      " [0.         0.         0.         1.        ]]\n",
      "\n",
      "Key Metrics Summary:\n",
      "  balanced_accuracy   : 0.7822\n",
      "  roc_auc_weighted    : 0.9213\n",
      "  mcc                 : 0.4318\n",
      "  f1_macro            : 0.4733\n",
      "  f1_weighted         : 0.8261\n",
      "LSTM_Bi_NoAtt.zip saved at /kaggle/working/LSTM_Bi_NoAtt.zip | Size: 1.92 MB\n",
      "\n",
      "============================== Experiment 9/12: LSTM_Uni_dot ==============================\n",
      "Using 2 GPUs via DataParallel!\n",
      "Training model: LSTM_Uni_dot for 60 epochs...\n",
      "Starting training for 60 epochs on cuda.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5fa09ebf1af4297863a00e09948dfd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/60 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Summary -> Avg. Loss: 0.8494, Accuracy: 75.04%\n",
      "Epoch 2 Summary -> Avg. Loss: 0.7888, Accuracy: 76.07%\n",
      "Epoch 3 Summary -> Avg. Loss: 0.7619, Accuracy: 76.44%\n",
      "Epoch 4 Summary -> Avg. Loss: 0.7394, Accuracy: 77.03%\n",
      "Epoch 5 Summary -> Avg. Loss: 0.7250, Accuracy: 77.29%\n",
      "Epoch 6 Summary -> Avg. Loss: 0.7040, Accuracy: 77.43%\n",
      "Epoch 7 Summary -> Avg. Loss: 0.6959, Accuracy: 77.88%\n",
      "Epoch 8 Summary -> Avg. Loss: 0.6782, Accuracy: 77.81%\n",
      "Epoch 9 Summary -> Avg. Loss: 0.6741, Accuracy: 77.93%\n",
      "Epoch 10 Summary -> Avg. Loss: 0.6549, Accuracy: 78.12%\n",
      "Epoch 11 Summary -> Avg. Loss: 0.6894, Accuracy: 77.35%\n",
      "Epoch 12 Summary -> Avg. Loss: 0.6765, Accuracy: 77.10%\n",
      "Epoch 13 Summary -> Avg. Loss: 0.6486, Accuracy: 77.52%\n",
      "Epoch 14 Summary -> Avg. Loss: 0.6499, Accuracy: 78.04%\n",
      "Epoch 15 Summary -> Avg. Loss: 0.6460, Accuracy: 77.99%\n",
      "Epoch 16 Summary -> Avg. Loss: 0.6888, Accuracy: 77.77%\n",
      "Epoch 17 Summary -> Avg. Loss: 0.6864, Accuracy: 77.85%\n",
      "Epoch 18 Summary -> Avg. Loss: 0.6457, Accuracy: 78.47%\n",
      "Epoch 19 Summary -> Avg. Loss: 0.6174, Accuracy: 78.79%\n",
      "Epoch 20 Summary -> Avg. Loss: 0.6208, Accuracy: 78.48%\n",
      "Epoch 21 Summary -> Avg. Loss: 0.5930, Accuracy: 79.05%\n",
      "Epoch 22 Summary -> Avg. Loss: 0.5873, Accuracy: 79.24%\n",
      "Epoch 23 Summary -> Avg. Loss: 0.5679, Accuracy: 79.81%\n",
      "Epoch 24 Summary -> Avg. Loss: 0.5630, Accuracy: 79.82%\n",
      "Epoch 25 Summary -> Avg. Loss: 0.5538, Accuracy: 79.94%\n",
      "Epoch 26 Summary -> Avg. Loss: 0.5364, Accuracy: 80.30%\n",
      "Epoch 27 Summary -> Avg. Loss: 0.5214, Accuracy: 80.45%\n",
      "Epoch 28 Summary -> Avg. Loss: 0.5010, Accuracy: 80.83%\n",
      "Epoch 29 Summary -> Avg. Loss: 0.5119, Accuracy: 80.74%\n",
      "Epoch 30 Summary -> Avg. Loss: 0.4844, Accuracy: 80.99%\n",
      "Epoch 31 Summary -> Avg. Loss: 0.4947, Accuracy: 81.27%\n",
      "Epoch 32 Summary -> Avg. Loss: 0.4735, Accuracy: 81.66%\n",
      "Epoch 33 Summary -> Avg. Loss: 0.4766, Accuracy: 80.63%\n",
      "Epoch 34 Summary -> Avg. Loss: 0.4534, Accuracy: 81.83%\n",
      "Epoch 35 Summary -> Avg. Loss: 0.4556, Accuracy: 81.91%\n",
      "Epoch 36 Summary -> Avg. Loss: 0.4570, Accuracy: 81.82%\n",
      "Epoch 37 Summary -> Avg. Loss: 0.4507, Accuracy: 81.95%\n",
      "Epoch 38 Summary -> Avg. Loss: 0.4262, Accuracy: 82.31%\n",
      "Epoch 39 Summary -> Avg. Loss: 0.4288, Accuracy: 82.50%\n",
      "Epoch 40 Summary -> Avg. Loss: 0.4141, Accuracy: 82.84%\n",
      "Epoch 41 Summary -> Avg. Loss: 0.4139, Accuracy: 83.08%\n",
      "Epoch 42 Summary -> Avg. Loss: 0.3938, Accuracy: 83.34%\n",
      "Epoch 43 Summary -> Avg. Loss: 0.4352, Accuracy: 83.36%\n",
      "Epoch 44 Summary -> Avg. Loss: 0.3897, Accuracy: 83.82%\n",
      "Epoch 45 Summary -> Avg. Loss: 0.4258, Accuracy: 83.66%\n",
      "Epoch 46 Summary -> Avg. Loss: 0.3818, Accuracy: 84.15%\n",
      "Epoch 47 Summary -> Avg. Loss: 0.3647, Accuracy: 84.71%\n",
      "Epoch 48 Summary -> Avg. Loss: 0.3984, Accuracy: 84.02%\n",
      "Epoch 49 Summary -> Avg. Loss: 0.3699, Accuracy: 84.13%\n",
      "Epoch 50 Summary -> Avg. Loss: 0.4097, Accuracy: 84.04%\n",
      "Epoch 51 Summary -> Avg. Loss: 0.3547, Accuracy: 84.70%\n",
      "Epoch 52 Summary -> Avg. Loss: 0.3572, Accuracy: 84.70%\n",
      "Epoch 53 Summary -> Avg. Loss: 0.3509, Accuracy: 84.91%\n",
      "Epoch 54 Summary -> Avg. Loss: 0.3438, Accuracy: 85.14%\n",
      "Epoch 55 Summary -> Avg. Loss: 0.3519, Accuracy: 84.77%\n",
      "Epoch 56 Summary -> Avg. Loss: 0.3592, Accuracy: 84.80%\n",
      "Epoch 57 Summary -> Avg. Loss: 0.3546, Accuracy: 85.48%\n",
      "Epoch 58 Summary -> Avg. Loss: 0.3304, Accuracy: 85.62%\n",
      "Epoch 59 Summary -> Avg. Loss: 0.3264, Accuracy: 86.02%\n",
      "Epoch 60 Summary -> Avg. Loss: 0.3107, Accuracy: 86.07%\n",
      "\n",
      "Total Train Time: 0h 33m 11s\n",
      "Evaluating model: LSTM_Uni_dot...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating (LSTM_Uni_dot):   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= LSTM_Uni_dot =================\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Flare     0.9912    0.8424    0.9108      1878\n",
      "     C-Class     0.3995    0.8429    0.5421       210\n",
      "     M-Class     0.3953    0.8718    0.5440        39\n",
      "     X-Class     0.6667    1.0000    0.8000         4\n",
      "\n",
      "    accuracy                         0.8433      2131\n",
      "   macro avg     0.6132    0.8893    0.6992      2131\n",
      "weighted avg     0.9214    0.8433    0.8675      2131\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix:\n",
      " [[0.84238552 0.1400426  0.01757188 0.        ]\n",
      " [0.06666667 0.84285714 0.09047619 0.        ]\n",
      " [0.         0.07692308 0.87179487 0.05128205]\n",
      " [0.         0.         0.         1.        ]]\n",
      "\n",
      "Key Metrics Summary:\n",
      "  balanced_accuracy   : 0.8893\n",
      "  roc_auc_weighted    : 0.9476\n",
      "  mcc                 : 0.5587\n",
      "  f1_macro            : 0.6992\n",
      "  f1_weighted         : 0.8675\n",
      "LSTM_Uni_dot.zip saved at /kaggle/working/LSTM_Uni_dot.zip | Size: 0.73 MB\n",
      "\n",
      "============================== Experiment 10/12: LSTM_Bi_dot ==============================\n",
      "Using 2 GPUs via DataParallel!\n",
      "Training model: LSTM_Bi_dot for 60 epochs...\n",
      "Starting training for 60 epochs on cuda.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f63fb529a34914b0868dd3737cca0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/60 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Summary -> Avg. Loss: 0.8387, Accuracy: 75.31%\n",
      "Epoch 2 Summary -> Avg. Loss: 0.7743, Accuracy: 76.25%\n",
      "Epoch 3 Summary -> Avg. Loss: 0.7366, Accuracy: 77.02%\n",
      "Epoch 4 Summary -> Avg. Loss: 0.7199, Accuracy: 77.35%\n",
      "Epoch 5 Summary -> Avg. Loss: 0.7068, Accuracy: 77.03%\n",
      "Epoch 6 Summary -> Avg. Loss: 0.6903, Accuracy: 77.44%\n",
      "Epoch 7 Summary -> Avg. Loss: 0.6779, Accuracy: 77.86%\n",
      "Epoch 8 Summary -> Avg. Loss: 0.6629, Accuracy: 78.23%\n",
      "Epoch 9 Summary -> Avg. Loss: 0.6384, Accuracy: 78.14%\n",
      "Epoch 10 Summary -> Avg. Loss: 0.6315, Accuracy: 78.83%\n",
      "Epoch 11 Summary -> Avg. Loss: 0.6234, Accuracy: 78.45%\n",
      "Epoch 12 Summary -> Avg. Loss: 0.6042, Accuracy: 78.59%\n",
      "Epoch 13 Summary -> Avg. Loss: 0.5859, Accuracy: 79.19%\n",
      "Epoch 14 Summary -> Avg. Loss: 0.5844, Accuracy: 78.98%\n",
      "Epoch 15 Summary -> Avg. Loss: 0.5787, Accuracy: 79.40%\n",
      "Epoch 16 Summary -> Avg. Loss: 0.5837, Accuracy: 79.09%\n",
      "Epoch 17 Summary -> Avg. Loss: 0.5718, Accuracy: 79.38%\n",
      "Epoch 18 Summary -> Avg. Loss: 0.5653, Accuracy: 79.77%\n",
      "Epoch 19 Summary -> Avg. Loss: 0.5349, Accuracy: 80.32%\n",
      "Epoch 20 Summary -> Avg. Loss: 0.5206, Accuracy: 80.56%\n",
      "Epoch 21 Summary -> Avg. Loss: 0.5338, Accuracy: 80.83%\n",
      "Epoch 22 Summary -> Avg. Loss: 0.4924, Accuracy: 81.35%\n",
      "Epoch 23 Summary -> Avg. Loss: 0.4844, Accuracy: 81.77%\n",
      "Epoch 24 Summary -> Avg. Loss: 0.4630, Accuracy: 82.35%\n",
      "Epoch 25 Summary -> Avg. Loss: 0.4573, Accuracy: 82.31%\n",
      "Epoch 26 Summary -> Avg. Loss: 0.4393, Accuracy: 83.06%\n",
      "Epoch 27 Summary -> Avg. Loss: 0.4197, Accuracy: 83.62%\n",
      "Epoch 28 Summary -> Avg. Loss: 0.4144, Accuracy: 83.96%\n",
      "Epoch 29 Summary -> Avg. Loss: 0.3974, Accuracy: 84.16%\n",
      "Epoch 30 Summary -> Avg. Loss: 0.3736, Accuracy: 84.74%\n",
      "Epoch 31 Summary -> Avg. Loss: 0.3684, Accuracy: 84.91%\n",
      "Epoch 32 Summary -> Avg. Loss: 0.3619, Accuracy: 85.21%\n",
      "Epoch 33 Summary -> Avg. Loss: 0.3581, Accuracy: 85.67%\n",
      "Epoch 34 Summary -> Avg. Loss: 0.3412, Accuracy: 85.99%\n",
      "Epoch 35 Summary -> Avg. Loss: 0.3379, Accuracy: 86.56%\n",
      "Epoch 36 Summary -> Avg. Loss: 0.3213, Accuracy: 86.83%\n",
      "Epoch 37 Summary -> Avg. Loss: 0.3249, Accuracy: 86.90%\n",
      "Epoch 38 Summary -> Avg. Loss: 0.3049, Accuracy: 87.24%\n",
      "Epoch 39 Summary -> Avg. Loss: 0.3129, Accuracy: 87.48%\n",
      "Epoch 40 Summary -> Avg. Loss: 0.2975, Accuracy: 87.54%\n",
      "Epoch 41 Summary -> Avg. Loss: 0.2767, Accuracy: 88.33%\n",
      "Epoch 42 Summary -> Avg. Loss: 0.3007, Accuracy: 87.82%\n",
      "Epoch 43 Summary -> Avg. Loss: 0.3293, Accuracy: 88.15%\n",
      "Epoch 44 Summary -> Avg. Loss: 0.2615, Accuracy: 89.21%\n",
      "Epoch 45 Summary -> Avg. Loss: 0.2664, Accuracy: 89.18%\n",
      "Epoch 46 Summary -> Avg. Loss: 0.2636, Accuracy: 89.11%\n",
      "Epoch 47 Summary -> Avg. Loss: 0.2341, Accuracy: 89.53%\n",
      "Epoch 48 Summary -> Avg. Loss: 0.2539, Accuracy: 89.21%\n",
      "Epoch 49 Summary -> Avg. Loss: 0.2440, Accuracy: 89.89%\n",
      "Epoch 50 Summary -> Avg. Loss: 0.2260, Accuracy: 90.31%\n",
      "Epoch 51 Summary -> Avg. Loss: 0.2466, Accuracy: 89.66%\n",
      "Epoch 52 Summary -> Avg. Loss: 0.2176, Accuracy: 90.61%\n",
      "Epoch 53 Summary -> Avg. Loss: 0.2209, Accuracy: 90.13%\n",
      "Epoch 54 Summary -> Avg. Loss: 0.2140, Accuracy: 90.78%\n",
      "Epoch 55 Summary -> Avg. Loss: 0.2108, Accuracy: 90.47%\n",
      "Epoch 56 Summary -> Avg. Loss: 0.1948, Accuracy: 91.16%\n",
      "Epoch 57 Summary -> Avg. Loss: 0.2276, Accuracy: 90.88%\n",
      "Epoch 58 Summary -> Avg. Loss: 0.2089, Accuracy: 90.85%\n",
      "Epoch 59 Summary -> Avg. Loss: 0.1893, Accuracy: 91.54%\n",
      "Epoch 60 Summary -> Avg. Loss: 0.1989, Accuracy: 91.76%\n",
      "\n",
      "Total Train Time: 1h 1m 31s\n",
      "Evaluating model: LSTM_Bi_dot...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating (LSTM_Bi_dot):   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= LSTM_Bi_dot =================\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Flare     0.9903    0.9201    0.9539      1878\n",
      "     C-Class     0.5839    0.8952    0.7068       210\n",
      "     M-Class     0.6316    0.9231    0.7500        39\n",
      "     X-Class     0.5714    1.0000    0.7273         4\n",
      "\n",
      "    accuracy                         0.9179      2131\n",
      "   macro avg     0.6943    0.9346    0.7845      2131\n",
      "weighted avg     0.9429    0.9179    0.9254      2131\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix:\n",
      " [[0.9201278  0.07082002 0.00905218 0.        ]\n",
      " [0.08095238 0.8952381  0.01904762 0.0047619 ]\n",
      " [0.         0.02564103 0.92307692 0.05128205]\n",
      " [0.         0.         0.         1.        ]]\n",
      "\n",
      "Key Metrics Summary:\n",
      "  balanced_accuracy   : 0.9346\n",
      "  roc_auc_weighted    : 0.9747\n",
      "  mcc                 : 0.7080\n",
      "  f1_macro            : 0.7845\n",
      "  f1_weighted         : 0.9254\n",
      "LSTM_Bi_dot.zip saved at /kaggle/working/LSTM_Bi_dot.zip | Size: 1.92 MB\n",
      "\n",
      "============================== Experiment 11/12: LSTM_Uni_concat ==============================\n",
      "Using 2 GPUs via DataParallel!\n",
      "Training model: LSTM_Uni_concat for 60 epochs...\n",
      "Starting training for 60 epochs on cuda.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6ad3fe1ead49ee8e62f4033ebcafb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/60 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Summary -> Avg. Loss: 0.8491, Accuracy: 74.96%\n",
      "Epoch 2 Summary -> Avg. Loss: 0.7864, Accuracy: 75.90%\n",
      "Epoch 3 Summary -> Avg. Loss: 0.7601, Accuracy: 76.28%\n",
      "Epoch 4 Summary -> Avg. Loss: 0.7298, Accuracy: 76.97%\n",
      "Epoch 5 Summary -> Avg. Loss: 0.7034, Accuracy: 77.36%\n",
      "Epoch 6 Summary -> Avg. Loss: 0.6916, Accuracy: 77.69%\n",
      "Epoch 7 Summary -> Avg. Loss: 0.6700, Accuracy: 77.82%\n",
      "Epoch 8 Summary -> Avg. Loss: 0.6619, Accuracy: 77.94%\n",
      "Epoch 9 Summary -> Avg. Loss: 0.6485, Accuracy: 78.02%\n",
      "Epoch 10 Summary -> Avg. Loss: 0.6354, Accuracy: 78.12%\n",
      "Epoch 11 Summary -> Avg. Loss: 0.6153, Accuracy: 78.26%\n",
      "Epoch 12 Summary -> Avg. Loss: 0.6064, Accuracy: 78.73%\n",
      "Epoch 13 Summary -> Avg. Loss: 0.6028, Accuracy: 78.81%\n",
      "Epoch 14 Summary -> Avg. Loss: 0.5859, Accuracy: 79.21%\n",
      "Epoch 15 Summary -> Avg. Loss: 0.5828, Accuracy: 78.96%\n",
      "Epoch 16 Summary -> Avg. Loss: 0.5874, Accuracy: 78.64%\n",
      "Epoch 17 Summary -> Avg. Loss: 0.6048, Accuracy: 78.31%\n",
      "Epoch 18 Summary -> Avg. Loss: 0.6672, Accuracy: 77.23%\n",
      "Epoch 19 Summary -> Avg. Loss: 0.7186, Accuracy: 77.09%\n",
      "Epoch 20 Summary -> Avg. Loss: 0.6913, Accuracy: 76.77%\n",
      "Epoch 21 Summary -> Avg. Loss: 0.6641, Accuracy: 77.61%\n",
      "Epoch 22 Summary -> Avg. Loss: 0.6737, Accuracy: 77.41%\n",
      "Epoch 23 Summary -> Avg. Loss: 0.6773, Accuracy: 77.63%\n",
      "Epoch 24 Summary -> Avg. Loss: 0.6734, Accuracy: 77.31%\n",
      "Epoch 25 Summary -> Avg. Loss: 0.6849, Accuracy: 77.35%\n",
      "Epoch 26 Summary -> Avg. Loss: 0.6650, Accuracy: 77.53%\n",
      "Epoch 27 Summary -> Avg. Loss: 0.6578, Accuracy: 77.48%\n",
      "Epoch 28 Summary -> Avg. Loss: 0.6343, Accuracy: 78.17%\n",
      "Epoch 29 Summary -> Avg. Loss: 0.6138, Accuracy: 78.48%\n",
      "Epoch 30 Summary -> Avg. Loss: 0.6079, Accuracy: 78.24%\n",
      "Epoch 31 Summary -> Avg. Loss: 0.5654, Accuracy: 79.21%\n",
      "Epoch 32 Summary -> Avg. Loss: 0.5698, Accuracy: 79.39%\n",
      "Epoch 33 Summary -> Avg. Loss: 0.5513, Accuracy: 79.46%\n",
      "Epoch 34 Summary -> Avg. Loss: 0.5131, Accuracy: 80.31%\n",
      "Epoch 35 Summary -> Avg. Loss: 0.5304, Accuracy: 80.06%\n",
      "Epoch 36 Summary -> Avg. Loss: 0.5172, Accuracy: 80.14%\n",
      "Epoch 37 Summary -> Avg. Loss: 0.5533, Accuracy: 80.08%\n",
      "Epoch 38 Summary -> Avg. Loss: 0.5016, Accuracy: 80.40%\n",
      "Epoch 39 Summary -> Avg. Loss: 0.5083, Accuracy: 80.40%\n",
      "Epoch 40 Summary -> Avg. Loss: 0.4909, Accuracy: 80.98%\n",
      "Epoch 41 Summary -> Avg. Loss: 0.4896, Accuracy: 80.56%\n",
      "Epoch 42 Summary -> Avg. Loss: 0.4605, Accuracy: 81.33%\n",
      "Epoch 43 Summary -> Avg. Loss: 0.5478, Accuracy: 80.55%\n",
      "Epoch 44 Summary -> Avg. Loss: 0.5169, Accuracy: 80.93%\n",
      "Epoch 45 Summary -> Avg. Loss: 0.4735, Accuracy: 81.16%\n",
      "Epoch 46 Summary -> Avg. Loss: 0.4599, Accuracy: 81.32%\n",
      "Epoch 47 Summary -> Avg. Loss: 0.4464, Accuracy: 81.43%\n",
      "Epoch 48 Summary -> Avg. Loss: 0.4853, Accuracy: 80.88%\n",
      "Epoch 49 Summary -> Avg. Loss: 0.4382, Accuracy: 81.68%\n",
      "Epoch 50 Summary -> Avg. Loss: 0.4437, Accuracy: 81.37%\n",
      "Epoch 51 Summary -> Avg. Loss: 0.4090, Accuracy: 82.04%\n",
      "Epoch 52 Summary -> Avg. Loss: 0.4826, Accuracy: 80.64%\n",
      "Epoch 53 Summary -> Avg. Loss: 0.4534, Accuracy: 81.21%\n",
      "Epoch 54 Summary -> Avg. Loss: 0.4365, Accuracy: 80.80%\n",
      "Epoch 55 Summary -> Avg. Loss: 0.4310, Accuracy: 81.03%\n",
      "Epoch 56 Summary -> Avg. Loss: 0.5025, Accuracy: 79.99%\n",
      "Epoch 57 Summary -> Avg. Loss: 0.4812, Accuracy: 80.10%\n",
      "Epoch 58 Summary -> Avg. Loss: 0.4920, Accuracy: 80.44%\n",
      "Epoch 59 Summary -> Avg. Loss: 0.4606, Accuracy: 81.26%\n",
      "Epoch 60 Summary -> Avg. Loss: 0.5148, Accuracy: 80.86%\n",
      "\n",
      "Total Train Time: 0h 33m 21s\n",
      "Evaluating model: LSTM_Uni_concat...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating (LSTM_Uni_concat):   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= LSTM_Uni_concat =================\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Flare     0.9870    0.8056    0.8871      1878\n",
      "     C-Class     0.3199    0.7571    0.4498       210\n",
      "     M-Class     0.2935    0.6923    0.4122        39\n",
      "     X-Class     0.3333    0.7500    0.4615         4\n",
      "\n",
      "    accuracy                         0.7987      2131\n",
      "   macro avg     0.4834    0.7513    0.5527      2131\n",
      "weighted avg     0.9073    0.7987    0.8345      2131\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix:\n",
      " [[8.05644302e-01 1.74653887e-01 1.91693291e-02 5.32481363e-04]\n",
      " [9.52380952e-02 7.57142857e-01 1.33333333e-01 1.42857143e-02]\n",
      " [0.00000000e+00 2.56410256e-01 6.92307692e-01 5.12820513e-02]\n",
      " [0.00000000e+00 0.00000000e+00 2.50000000e-01 7.50000000e-01]]\n",
      "\n",
      "Key Metrics Summary:\n",
      "  balanced_accuracy   : 0.7513\n",
      "  roc_auc_weighted    : 0.9284\n",
      "  mcc                 : 0.4674\n",
      "  f1_macro            : 0.5527\n",
      "  f1_weighted         : 0.8345\n",
      "LSTM_Uni_concat.zip saved at /kaggle/working/LSTM_Uni_concat.zip | Size: 0.73 MB\n",
      "\n",
      "============================== Experiment 12/12: LSTM_Bi_concat ==============================\n",
      "Using 2 GPUs via DataParallel!\n",
      "Training model: LSTM_Bi_concat for 60 epochs...\n",
      "Starting training for 60 epochs on cuda.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6560f232076546c2b51494ef36f5e743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/60 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Summary -> Avg. Loss: 0.8318, Accuracy: 75.57%\n",
      "Epoch 2 Summary -> Avg. Loss: 0.7688, Accuracy: 76.58%\n",
      "Epoch 3 Summary -> Avg. Loss: 0.7331, Accuracy: 76.80%\n",
      "Epoch 4 Summary -> Avg. Loss: 0.7099, Accuracy: 77.12%\n",
      "Epoch 5 Summary -> Avg. Loss: 0.6942, Accuracy: 77.49%\n",
      "Epoch 6 Summary -> Avg. Loss: 0.6689, Accuracy: 77.89%\n",
      "Epoch 7 Summary -> Avg. Loss: 0.6677, Accuracy: 77.90%\n",
      "Epoch 8 Summary -> Avg. Loss: 0.6411, Accuracy: 78.64%\n",
      "Epoch 9 Summary -> Avg. Loss: 0.6162, Accuracy: 78.99%\n",
      "Epoch 10 Summary -> Avg. Loss: 0.6033, Accuracy: 79.03%\n",
      "Epoch 11 Summary -> Avg. Loss: 0.5778, Accuracy: 79.39%\n",
      "Epoch 12 Summary -> Avg. Loss: 0.5657, Accuracy: 79.99%\n",
      "Epoch 13 Summary -> Avg. Loss: 0.5557, Accuracy: 80.21%\n",
      "Epoch 14 Summary -> Avg. Loss: 0.5325, Accuracy: 80.40%\n",
      "Epoch 15 Summary -> Avg. Loss: 0.5165, Accuracy: 80.90%\n",
      "Epoch 16 Summary -> Avg. Loss: 0.4881, Accuracy: 81.36%\n",
      "Epoch 17 Summary -> Avg. Loss: 0.5015, Accuracy: 81.26%\n",
      "Epoch 18 Summary -> Avg. Loss: 0.4611, Accuracy: 82.14%\n",
      "Epoch 19 Summary -> Avg. Loss: 0.4566, Accuracy: 82.44%\n",
      "Epoch 20 Summary -> Avg. Loss: 0.4501, Accuracy: 82.75%\n",
      "Epoch 21 Summary -> Avg. Loss: 0.4179, Accuracy: 83.56%\n",
      "Epoch 22 Summary -> Avg. Loss: 0.3949, Accuracy: 84.13%\n",
      "Epoch 23 Summary -> Avg. Loss: 0.3927, Accuracy: 84.28%\n",
      "Epoch 24 Summary -> Avg. Loss: 0.3660, Accuracy: 85.11%\n",
      "Epoch 25 Summary -> Avg. Loss: 0.3846, Accuracy: 84.79%\n",
      "Epoch 26 Summary -> Avg. Loss: 0.3434, Accuracy: 85.80%\n",
      "Epoch 27 Summary -> Avg. Loss: 0.3521, Accuracy: 86.10%\n",
      "Epoch 28 Summary -> Avg. Loss: 0.4124, Accuracy: 85.20%\n",
      "Epoch 29 Summary -> Avg. Loss: 0.3289, Accuracy: 86.52%\n",
      "Epoch 30 Summary -> Avg. Loss: 0.3022, Accuracy: 87.21%\n",
      "Epoch 31 Summary -> Avg. Loss: 0.3153, Accuracy: 87.30%\n",
      "Epoch 32 Summary -> Avg. Loss: 0.3168, Accuracy: 87.11%\n",
      "Epoch 33 Summary -> Avg. Loss: 0.2960, Accuracy: 87.78%\n",
      "Epoch 34 Summary -> Avg. Loss: 0.2822, Accuracy: 88.31%\n",
      "Epoch 35 Summary -> Avg. Loss: 0.2753, Accuracy: 88.61%\n",
      "Epoch 36 Summary -> Avg. Loss: 0.2864, Accuracy: 88.21%\n",
      "Epoch 37 Summary -> Avg. Loss: 0.2838, Accuracy: 87.79%\n",
      "Epoch 38 Summary -> Avg. Loss: 0.2706, Accuracy: 88.53%\n",
      "Epoch 39 Summary -> Avg. Loss: 0.2666, Accuracy: 88.88%\n",
      "Epoch 40 Summary -> Avg. Loss: 0.2575, Accuracy: 89.20%\n",
      "Epoch 41 Summary -> Avg. Loss: 0.2511, Accuracy: 89.48%\n",
      "Epoch 42 Summary -> Avg. Loss: 0.2485, Accuracy: 89.45%\n",
      "Epoch 43 Summary -> Avg. Loss: 0.2383, Accuracy: 90.03%\n",
      "Epoch 44 Summary -> Avg. Loss: 0.2291, Accuracy: 90.26%\n",
      "Epoch 45 Summary -> Avg. Loss: 0.2146, Accuracy: 90.69%\n",
      "Epoch 46 Summary -> Avg. Loss: 0.2279, Accuracy: 90.49%\n",
      "Epoch 47 Summary -> Avg. Loss: 0.2093, Accuracy: 90.97%\n",
      "Epoch 48 Summary -> Avg. Loss: 0.2113, Accuracy: 90.77%\n",
      "Epoch 49 Summary -> Avg. Loss: 0.2440, Accuracy: 90.56%\n",
      "Epoch 50 Summary -> Avg. Loss: 0.2141, Accuracy: 90.95%\n",
      "Epoch 51 Summary -> Avg. Loss: 0.2261, Accuracy: 91.08%\n",
      "Epoch 52 Summary -> Avg. Loss: 0.2183, Accuracy: 91.13%\n",
      "Epoch 53 Summary -> Avg. Loss: 0.2444, Accuracy: 90.70%\n",
      "Epoch 54 Summary -> Avg. Loss: 0.1933, Accuracy: 91.57%\n",
      "Epoch 55 Summary -> Avg. Loss: 0.1941, Accuracy: 91.47%\n",
      "Epoch 56 Summary -> Avg. Loss: 0.2427, Accuracy: 90.79%\n",
      "Epoch 57 Summary -> Avg. Loss: 0.2154, Accuracy: 91.38%\n",
      "Epoch 58 Summary -> Avg. Loss: 0.2053, Accuracy: 91.38%\n",
      "Epoch 59 Summary -> Avg. Loss: 0.1816, Accuracy: 91.98%\n",
      "Epoch 60 Summary -> Avg. Loss: 0.1989, Accuracy: 91.66%\n",
      "\n",
      "Total Train Time: 1h 1m 38s\n",
      "Evaluating model: LSTM_Bi_concat...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating (LSTM_Bi_concat):   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= LSTM_Bi_concat =================\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Flare     0.9929    0.8962    0.9421      1878\n",
      "     C-Class     0.5179    0.8952    0.6562       210\n",
      "     M-Class     0.5217    0.9231    0.6667        39\n",
      "     X-Class     0.7500    0.7500    0.7500         4\n",
      "\n",
      "    accuracy                         0.8963      2131\n",
      "   macro avg     0.6956    0.8661    0.7537      2131\n",
      "weighted avg     0.9370    0.8963    0.9085      2131\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix:\n",
      " [[0.89616613 0.09158679 0.01224707 0.        ]\n",
      " [0.05714286 0.8952381  0.04285714 0.0047619 ]\n",
      " [0.         0.07692308 0.92307692 0.        ]\n",
      " [0.         0.         0.25       0.75      ]]\n",
      "\n",
      "Key Metrics Summary:\n",
      "  balanced_accuracy   : 0.8661\n",
      "  roc_auc_weighted    : 0.9693\n",
      "  mcc                 : 0.6634\n",
      "  f1_macro            : 0.7537\n",
      "  f1_weighted         : 0.9085\n",
      "LSTM_Bi_concat.zip saved at /kaggle/working/LSTM_Bi_concat.zip | Size: 1.92 MB\n",
      "\n",
      "============================== FINAL EXPERIMENT REPORT ==============================\n",
      "Total experiment time: 442.63 minutes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>model_type</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>attention</th>\n",
       "      <th>bidirectional</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>roc_auc_weighted</th>\n",
       "      <th>mcc</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>training_time_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LSTM_Bi_dot</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>dot</td>\n",
       "      <td>True</td>\n",
       "      <td>0.9346</td>\n",
       "      <td>0.9747</td>\n",
       "      <td>0.7080</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.9254</td>\n",
       "      <td>61.5377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LSTM_Bi_concat</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>concat</td>\n",
       "      <td>True</td>\n",
       "      <td>0.8661</td>\n",
       "      <td>0.9693</td>\n",
       "      <td>0.6634</td>\n",
       "      <td>0.7537</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>61.6548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LSTM_Uni_dot</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>dot</td>\n",
       "      <td>False</td>\n",
       "      <td>0.8893</td>\n",
       "      <td>0.9476</td>\n",
       "      <td>0.5587</td>\n",
       "      <td>0.6992</td>\n",
       "      <td>0.8675</td>\n",
       "      <td>33.1952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LSTM_Uni_concat</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>concat</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7513</td>\n",
       "      <td>0.9284</td>\n",
       "      <td>0.4674</td>\n",
       "      <td>0.5527</td>\n",
       "      <td>0.8345</td>\n",
       "      <td>33.3580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSTM_Uni_NoAtt</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.7765</td>\n",
       "      <td>0.9233</td>\n",
       "      <td>0.4628</td>\n",
       "      <td>0.5684</td>\n",
       "      <td>0.8285</td>\n",
       "      <td>31.1556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LSTM_Bi_NoAtt</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7822</td>\n",
       "      <td>0.9213</td>\n",
       "      <td>0.4318</td>\n",
       "      <td>0.4733</td>\n",
       "      <td>0.8261</td>\n",
       "      <td>59.8036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RNN_Uni_NoAtt</td>\n",
       "      <td>RNN</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>0.4763</td>\n",
       "      <td>0.9026</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>0.3956</td>\n",
       "      <td>0.8232</td>\n",
       "      <td>23.5624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RNN_Bi_dot</td>\n",
       "      <td>RNN</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>dot</td>\n",
       "      <td>True</td>\n",
       "      <td>0.7576</td>\n",
       "      <td>0.9120</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>0.4626</td>\n",
       "      <td>0.8251</td>\n",
       "      <td>30.2376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RNN_Uni_concat</td>\n",
       "      <td>RNN</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>concat</td>\n",
       "      <td>False</td>\n",
       "      <td>0.6985</td>\n",
       "      <td>0.9079</td>\n",
       "      <td>0.3929</td>\n",
       "      <td>0.4516</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>25.8786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RNN_Bi_concat</td>\n",
       "      <td>RNN</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>concat</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6332</td>\n",
       "      <td>0.9037</td>\n",
       "      <td>0.3757</td>\n",
       "      <td>0.4483</td>\n",
       "      <td>0.7757</td>\n",
       "      <td>28.7604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RNN_Uni_dot</td>\n",
       "      <td>RNN</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>dot</td>\n",
       "      <td>False</td>\n",
       "      <td>0.4698</td>\n",
       "      <td>0.8977</td>\n",
       "      <td>0.3718</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.7903</td>\n",
       "      <td>25.8295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RNN_Bi_NoAtt</td>\n",
       "      <td>RNN</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>0.6036</td>\n",
       "      <td>0.9065</td>\n",
       "      <td>0.3602</td>\n",
       "      <td>0.3850</td>\n",
       "      <td>0.7874</td>\n",
       "      <td>27.6475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           run_name model_type  num_layers  hidden_size attention  \\\n",
       "0       LSTM_Bi_dot       LSTM           2          128       dot   \n",
       "1    LSTM_Bi_concat       LSTM           2          128    concat   \n",
       "2      LSTM_Uni_dot       LSTM           2          128       dot   \n",
       "3   LSTM_Uni_concat       LSTM           2          128    concat   \n",
       "4    LSTM_Uni_NoAtt       LSTM           2          128      None   \n",
       "5     LSTM_Bi_NoAtt       LSTM           2          128      None   \n",
       "6     RNN_Uni_NoAtt        RNN           2          128      None   \n",
       "7        RNN_Bi_dot        RNN           2          128       dot   \n",
       "8    RNN_Uni_concat        RNN           2          128    concat   \n",
       "9     RNN_Bi_concat        RNN           2          128    concat   \n",
       "10      RNN_Uni_dot        RNN           2          128       dot   \n",
       "11     RNN_Bi_NoAtt        RNN           2          128      None   \n",
       "\n",
       "    bidirectional  balanced_accuracy  roc_auc_weighted    mcc  f1_macro  \\\n",
       "0            True             0.9346            0.9747 0.7080    0.7845   \n",
       "1            True             0.8661            0.9693 0.6634    0.7537   \n",
       "2           False             0.8893            0.9476 0.5587    0.6992   \n",
       "3           False             0.7513            0.9284 0.4674    0.5527   \n",
       "4           False             0.7765            0.9233 0.4628    0.5684   \n",
       "5            True             0.7822            0.9213 0.4318    0.4733   \n",
       "6           False             0.4763            0.9026 0.4025    0.3956   \n",
       "7            True             0.7576            0.9120 0.3934    0.4626   \n",
       "8           False             0.6985            0.9079 0.3929    0.4516   \n",
       "9            True             0.6332            0.9037 0.3757    0.4483   \n",
       "10          False             0.4698            0.8977 0.3718    0.3818   \n",
       "11           True             0.6036            0.9065 0.3602    0.3850   \n",
       "\n",
       "    f1_weighted  training_time_min  \n",
       "0        0.9254            61.5377  \n",
       "1        0.9085            61.6548  \n",
       "2        0.8675            33.1952  \n",
       "3        0.8345            33.3580  \n",
       "4        0.8285            31.1556  \n",
       "5        0.8261            59.8036  \n",
       "6        0.8232            23.5624  \n",
       "7        0.8251            30.2376  \n",
       "8        0.8077            25.8786  \n",
       "9        0.7757            28.7604  \n",
       "10       0.7903            25.8295  \n",
       "11       0.7874            27.6475  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "results_log = []\n",
    "total_start_time = time.time()\n",
    "\n",
    "for i, config in enumerate(experiments):\n",
    "    print(f\"\\n{'='*30} Experiment {i+1}/{len(experiments)}: {config['run_name']} {'='*30}\")\n",
    "    \n",
    "    experiment_start_time = time.time()\n",
    "    \n",
    "    if config[\"model_type\"] == \"RNN\":\n",
    "        model = AttentiveRNN(\n",
    "            input_size=len(features),\n",
    "            hidden_size=config[\"hidden_size\"],\n",
    "            num_layers=config[\"num_layers\"],\n",
    "            num_classes=len(class_names),\n",
    "            attention=config[\"attention\"],\n",
    "            bidirectional=config[\"bidirectional\"]\n",
    "        )\n",
    "    else: # LSTM\n",
    "        model = AttentiveLSTM(\n",
    "            input_size=len(features),\n",
    "            hidden_size=config[\"hidden_size\"],\n",
    "            num_classes=len(class_names),\n",
    "            num_layers=config[\"num_layers\"],\n",
    "            attention=config[\"attention\"],\n",
    "            bidirectional=config[\"bidirectional\"]\n",
    "        )\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs via DataParallel!\")\n",
    "        model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "    \n",
    "    print(f\"Training model: {config['run_name']} for {config['epochs']} epochs...\")\n",
    "    training(model, device, criterion, optimizer, train, train_epochs=config[\"epochs\"])\n",
    "    \n",
    "    print(f\"Evaluating model: {config['run_name']}...\")\n",
    "    eval_metrics = eval_detailed(model, device, dev, report_title=config['run_name'])\n",
    "    \n",
    "    experiment_time = time.time() - experiment_start_time\n",
    "    save_model_as_zip(model, model_name=config['run_name'])\n",
    "    \n",
    "    run_result = {\n",
    "        \"run_name\": config[\"run_name\"],\n",
    "        \"model_type\": config[\"model_type\"],\n",
    "        \"num_layers\": config[\"num_layers\"],\n",
    "        \"hidden_size\": config[\"hidden_size\"],\n",
    "        \"attention\": str(config[\"attention\"]),\n",
    "        \"bidirectional\": config[\"bidirectional\"],\n",
    "        **eval_metrics,\n",
    "        \"training_time_min\": experiment_time / 60\n",
    "    }\n",
    "    results_log.append(run_result)\n",
    "    \n",
    "    pd.DataFrame(results_log).to_csv(\"experiment_report_intermediate.csv\", index=False)\n",
    "\n",
    "\n",
    "print(f\"\\n{'='*30} FINAL EXPERIMENT REPORT {'='*30}\")\n",
    "total_run_time = time.time() - total_start_time\n",
    "print(f\"Total experiment time: {total_run_time/60:.2f} minutes\")\n",
    "\n",
    "results_df = pd.DataFrame(results_log)\n",
    "results_df = results_df.sort_values(by=\"mcc\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "display(results_df)\n",
    "\n",
    "results_df.to_csv(\"experiment_report_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Funrther"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T04:55:16.977219Z",
     "iopub.status.busy": "2025-11-10T04:55:16.976567Z",
     "iopub.status.idle": "2025-11-10T04:55:16.982194Z",
     "shell.execute_reply": "2025-11-10T04:55:16.981568Z",
     "shell.execute_reply.started": "2025-11-10T04:55:16.977194Z"
    }
   },
   "outputs": [],
   "source": [
    "def unzip_and_load_model(model, model_name, save_dir=\"/kaggle/working\"):\n",
    "    zip_path = os.path.join(save_dir, f\"{model_name}.zip\")\n",
    "    model_path = os.path.join(save_dir, f\"{model_name}.pth\")\n",
    "\n",
    "    # Unzip the model\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(save_dir)\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found after extraction: {model_path}\")\n",
    "\n",
    "    # Load model weights\n",
    "    model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "\n",
    "    os.remove(model_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "results_log = []\n",
    "total_start_time = time.time()\n",
    "\n",
    "for i, config in enumerate(experiments):\n",
    "    print(f\"\\n{'='*30} Experiment {i+1+20}/{len(experiments)}: {config['run_name']} {'='*30}\")\n",
    "    \n",
    "    experiment_start_time = time.time()\n",
    "    \n",
    "    if config[\"model_type\"] == \"RNN\":\n",
    "        model = AttentiveRNN(\n",
    "            input_size=len(features),\n",
    "            hidden_size=config[\"hidden_size\"],\n",
    "            num_layers=config[\"num_layers\"],\n",
    "            num_classes=len(class_names),\n",
    "            attention=config[\"attention\"],\n",
    "            bidirectional=config[\"bidirectional\"]\n",
    "        )\n",
    "    else: # LSTM\n",
    "        model = AttentiveLSTM(\n",
    "            input_size=len(features),\n",
    "            hidden_size=config[\"hidden_size\"],\n",
    "            num_classes=len(class_names),\n",
    "            num_layers=config[\"num_layers\"],\n",
    "            attention=config[\"attention\"],\n",
    "            bidirectional=config[\"bidirectional\"]\n",
    "        )\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs via DataParallel!\")\n",
    "        model = nn.DataParallel(model)\n",
    "        \n",
    "    model = unzip_and_load_model(model, config['run_name'])\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    print(f\"Training model: {config['run_name']} for {config['epochs']} epochs...\")\n",
    "    training(model, device, criterion, optimizer, train, train_epochs=config[\"epochs\"])\n",
    "    \n",
    "    print(f\"Evaluating model: {config['run_name']}...\")\n",
    "    eval_metrics = eval_detailed(model, device, dev, report_title=config['run_name'])\n",
    "    \n",
    "    experiment_time = time.time() - experiment_start_time\n",
    "    save_model_as_zip(model, model_name=config['run_name'])\n",
    "    \n",
    "    run_result = {\n",
    "        \"run_name\": config[\"run_name\"],\n",
    "        \"model_type\": config[\"model_type\"],\n",
    "        \"num_layers\": config[\"num_layers\"],\n",
    "        \"hidden_size\": config[\"hidden_size\"],\n",
    "        \"attention\": str(config[\"attention\"]),\n",
    "        \"bidirectional\": config[\"bidirectional\"],\n",
    "        **eval_metrics,\n",
    "        \"training_time_min\": experiment_time / 60\n",
    "    }\n",
    "    results_log.append(run_result)\n",
    "    \n",
    "    pd.DataFrame(results_log).to_csv(\"experiment_report_intermediate.csv\", index=False)\n",
    "\n",
    "\n",
    "print(f\"\\n{'='*30} FINAL EXPERIMENT REPORT {'='*30}\")\n",
    "total_run_time = time.time() - total_start_time\n",
    "print(f\"Total experiment time: {total_run_time/60:.2f} minutes\")\n",
    "\n",
    "results_df = pd.DataFrame(results_log)\n",
    "results_df = results_df.sort_values(by=\"mcc\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "display(results_df)\n",
    "\n",
    "results_df.to_csv(\"experiment_report_final2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T06:55:45.187058Z",
     "iopub.status.busy": "2025-11-10T06:55:45.186494Z",
     "iopub.status.idle": "2025-11-10T06:55:45.565477Z",
     "shell.execute_reply": "2025-11-10T06:55:45.564732Z",
     "shell.execute_reply.started": "2025-11-10T06:55:45.187031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/ (stored 0%)\n",
      "  adding: kaggle/working/RNN_Uni_dot.zip (stored 0%)\n",
      "  adding: kaggle/working/LSTM_Bi_NoAtt.zip (stored 0%)\n",
      "  adding: kaggle/working/.virtual_documents/ (stored 0%)\n",
      "  adding: kaggle/working/RNN_Bi_concat.zip (stored 0%)\n",
      "  adding: kaggle/working/experiment_report_final.csv (deflated 50%)\n",
      "  adding: kaggle/working/LSTM_Uni_dot.zip (stored 0%)\n",
      "  adding: kaggle/working/LSTM_Bi_concat.zip (stored 0%)\n",
      "  adding: kaggle/working/LSTM_Bi_dot.zip (stored 0%)\n",
      "  adding: kaggle/working/RNN_Bi_NoAtt.zip (stored 0%)\n",
      "  adding: kaggle/working/RNN_Bi_dot.zip (stored 0%)\n",
      "  adding: kaggle/working/RNN_Uni_concat.zip (stored 0%)\n",
      "  adding: kaggle/working/experiment_report_intermediate.csv (deflated 42%)\n",
      "  adding: kaggle/working/RNN_Uni_NoAtt.zip (stored 0%)\n",
      "  adding: kaggle/working/scaler_params.csv (deflated 57%)\n",
      "  adding: kaggle/working/LSTM_Uni_NoAtt.zip (stored 0%)\n",
      "  adding: kaggle/working/LSTM_Uni_concat.zip (stored 0%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r Unihead.zip /kaggle/working/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Head Attention Bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T07:34:42.974566Z",
     "iopub.status.busy": "2025-11-10T07:34:42.974167Z",
     "iopub.status.idle": "2025-11-10T07:34:42.993427Z",
     "shell.execute_reply": "2025-11-10T07:34:42.992583Z",
     "shell.execute_reply.started": "2025-11-10T07:34:42.974539Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiHeadBiLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, num_heads=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        # BiLSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        # Multi-Head Attention\n",
    "        self.mha = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size * 2,\n",
    "            num_heads=num_heads,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X: (batch_size, seq_len, input_size)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(X)\n",
    "        # lstm_out: (batch_size, seq_len, hidden_size * num_directions)\n",
    "\n",
    "        attn_out, attn_weights = self.mha(lstm_out, lstm_out, lstm_out)\n",
    "        # attn_out: (batch_size, seq_len, hidden_size * num_directions)\n",
    "\n",
    "        context = torch.mean(attn_out, dim=1)\n",
    "        # context: (batch_size, hidden_size * num_directions)\n",
    "\n",
    "        output = self.fc(context)\n",
    "\n",
    "        return output, attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T07:43:38.635267Z",
     "iopub.status.busy": "2025-11-10T07:43:38.634457Z",
     "iopub.status.idle": "2025-11-10T07:43:38.642140Z",
     "shell.execute_reply": "2025-11-10T07:43:38.641361Z",
     "shell.execute_reply.started": "2025-11-10T07:43:38.635218Z"
    }
   },
   "outputs": [],
   "source": [
    "experiments = []\n",
    "\n",
    "# Experiment 1\n",
    "run_name = \"MH_Bi_LSTM_hs256_l2_h4\"\n",
    "config = {\n",
    "    \"run_name\": run_name,\n",
    "    \"hidden_size\": 256,\n",
    "    \"num_layers\": 2,\n",
    "    \"heads\": 4,\n",
    "    \"lr\": 0.001,\n",
    "    \"epochs\": 40\n",
    "}\n",
    "experiments.append(config)\n",
    "\n",
    "# Experiment 2\n",
    "run_name = \"MH_Bi_LSTM_hs128_l2_h8\"\n",
    "config = {\n",
    "    \"run_name\": run_name,\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 2,\n",
    "    \"heads\": 8,\n",
    "    \"lr\": 0.001,\n",
    "    \"epochs\": 40\n",
    "}\n",
    "experiments.append(config)\n",
    "\n",
    "# Experiment 3\n",
    "run_name = \"MH_Bi_LSTM_hs256_l3_h4\"\n",
    "config = {\n",
    "    \"run_name\": run_name,\n",
    "    \"hidden_size\": 256,\n",
    "    \"num_layers\": 3,\n",
    "    \"heads\": 4,\n",
    "    \"lr\": 0.001,\n",
    "    \"epochs\": 40\n",
    "}\n",
    "experiments.append(config)\n",
    "\n",
    "# Experiment 4\n",
    "run_name = \"MH_Bi_LSTM_hs128_l1_h8\"\n",
    "config = {\n",
    "    \"run_name\": run_name,\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 1,\n",
    "    \"heads\": 8,\n",
    "    \"lr\": 0.001,\n",
    "    \"epochs\": 40\n",
    "}\n",
    "experiments.append(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-10T07:43:42.820250Z",
     "iopub.status.busy": "2025-11-10T07:43:42.819781Z",
     "iopub.status.idle": "2025-11-10T16:34:32.557263Z",
     "shell.execute_reply": "2025-11-10T16:34:32.556639Z",
     "shell.execute_reply.started": "2025-11-10T07:43:42.820201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== Experiment 1/4: MH_Bi_LSTM_hs256_l2_h4 ==============================\n",
      "Using 2 GPUs via DataParallel!\n",
      "Training model: MH_Bi_LSTM_hs256_l2_h4 for 40 epochs...\n",
      "Starting training for 40 epochs on cuda.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1ebde2f97b493caeea963d0a20b250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/40 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Summary -> Avg. Loss: 0.8657, Accuracy: 74.97%\n",
      "Epoch 2 Summary -> Avg. Loss: 0.8290, Accuracy: 75.41%\n",
      "Epoch 3 Summary -> Avg. Loss: 0.7998, Accuracy: 76.49%\n",
      "Epoch 4 Summary -> Avg. Loss: 0.7778, Accuracy: 76.68%\n",
      "Epoch 5 Summary -> Avg. Loss: 0.7743, Accuracy: 76.38%\n",
      "Epoch 6 Summary -> Avg. Loss: 0.7523, Accuracy: 76.35%\n",
      "Epoch 7 Summary -> Avg. Loss: 0.7386, Accuracy: 76.39%\n",
      "Epoch 8 Summary -> Avg. Loss: 0.7222, Accuracy: 77.07%\n",
      "Epoch 9 Summary -> Avg. Loss: 0.7040, Accuracy: 76.99%\n",
      "Epoch 10 Summary -> Avg. Loss: 0.6897, Accuracy: 76.84%\n",
      "Epoch 11 Summary -> Avg. Loss: 0.6700, Accuracy: 77.21%\n",
      "Epoch 12 Summary -> Avg. Loss: 0.6474, Accuracy: 77.90%\n",
      "Epoch 13 Summary -> Avg. Loss: 0.6274, Accuracy: 78.22%\n",
      "Epoch 14 Summary -> Avg. Loss: 0.6209, Accuracy: 78.48%\n",
      "Epoch 15 Summary -> Avg. Loss: 0.5995, Accuracy: 78.90%\n",
      "Epoch 16 Summary -> Avg. Loss: 0.5893, Accuracy: 78.76%\n",
      "Epoch 17 Summary -> Avg. Loss: 0.5701, Accuracy: 79.25%\n",
      "Epoch 18 Summary -> Avg. Loss: 0.5571, Accuracy: 79.54%\n",
      "Epoch 19 Summary -> Avg. Loss: 0.5498, Accuracy: 79.53%\n",
      "Epoch 20 Summary -> Avg. Loss: 0.5298, Accuracy: 80.02%\n",
      "Epoch 21 Summary -> Avg. Loss: 0.5123, Accuracy: 80.54%\n",
      "Epoch 22 Summary -> Avg. Loss: 0.5087, Accuracy: 80.39%\n",
      "Epoch 23 Summary -> Avg. Loss: 0.4911, Accuracy: 80.98%\n",
      "Epoch 24 Summary -> Avg. Loss: 0.4752, Accuracy: 81.41%\n",
      "Epoch 25 Summary -> Avg. Loss: 0.4631, Accuracy: 81.61%\n",
      "Epoch 26 Summary -> Avg. Loss: 0.4478, Accuracy: 81.98%\n",
      "Epoch 27 Summary -> Avg. Loss: 0.4347, Accuracy: 82.42%\n",
      "Epoch 28 Summary -> Avg. Loss: 0.4235, Accuracy: 82.63%\n",
      "Epoch 29 Summary -> Avg. Loss: 0.4258, Accuracy: 82.87%\n",
      "Epoch 30 Summary -> Avg. Loss: 0.4254, Accuracy: 82.98%\n",
      "Epoch 31 Summary -> Avg. Loss: 0.5255, Accuracy: 82.79%\n",
      "Epoch 32 Summary -> Avg. Loss: 0.6711, Accuracy: 79.14%\n",
      "Epoch 33 Summary -> Avg. Loss: 0.6378, Accuracy: 78.77%\n",
      "Epoch 34 Summary -> Avg. Loss: 0.6200, Accuracy: 79.56%\n",
      "Epoch 35 Summary -> Avg. Loss: 0.5659, Accuracy: 80.67%\n",
      "Epoch 36 Summary -> Avg. Loss: 0.5435, Accuracy: 81.38%\n",
      "Epoch 37 Summary -> Avg. Loss: 0.4978, Accuracy: 81.85%\n",
      "Epoch 38 Summary -> Avg. Loss: 0.4761, Accuracy: 82.52%\n",
      "Epoch 39 Summary -> Avg. Loss: 0.4461, Accuracy: 83.22%\n",
      "Epoch 40 Summary -> Avg. Loss: 0.4345, Accuracy: 83.11%\n",
      "\n",
      "Total Train Time: 2h 53m 27s\n",
      "Evaluating model: MH_Bi_LSTM_hs256_l2_h4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating (MH_Bi_LSTM_hs256_l2_h4):   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= MH_Bi_LSTM_hs256_l2_h4 =================\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Flare     0.9839    0.8115    0.8894      1878\n",
      "     C-Class     0.3521    0.7143    0.4717       210\n",
      "     M-Class     0.2153    0.7949    0.3388        39\n",
      "     X-Class     0.3333    1.0000    0.5000         4\n",
      "\n",
      "    accuracy                         0.8020      2131\n",
      "   macro avg     0.4711    0.8302    0.5500      2131\n",
      "weighted avg     0.9063    0.8020    0.8374      2131\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix:\n",
      " [[0.8115016  0.14430245 0.04313099 0.00106496]\n",
      " [0.11904762 0.71428571 0.15238095 0.01428571]\n",
      " [0.         0.12820513 0.79487179 0.07692308]\n",
      " [0.         0.         0.         1.        ]]\n",
      "\n",
      "Key Metrics Summary:\n",
      "  balanced_accuracy   : 0.8302\n",
      "  roc_auc_weighted    : 0.9251\n",
      "  mcc                 : 0.4653\n",
      "  f1_macro            : 0.5500\n",
      "  f1_weighted         : 0.8374\n",
      "MH_Bi_LSTM_hs256_l2_h4.zip saved at /kaggle/working/MH_Bi_LSTM_hs256_l2_h4.zip | Size: 11.28 MB\n",
      "\n",
      "============================== Experiment 2/4: MH_Bi_LSTM_hs128_l2_h8 ==============================\n",
      "Using 2 GPUs via DataParallel!\n",
      "Training model: MH_Bi_LSTM_hs128_l2_h8 for 40 epochs...\n",
      "Starting training for 40 epochs on cuda.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e648efea33d480b9d16dac898a68e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/40 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Summary -> Avg. Loss: 0.8547, Accuracy: 75.16%\n",
      "Epoch 2 Summary -> Avg. Loss: 0.8068, Accuracy: 75.79%\n",
      "Epoch 3 Summary -> Avg. Loss: 0.7712, Accuracy: 76.66%\n",
      "Epoch 4 Summary -> Avg. Loss: 0.7457, Accuracy: 76.78%\n",
      "Epoch 5 Summary -> Avg. Loss: 0.7121, Accuracy: 77.39%\n",
      "Epoch 6 Summary -> Avg. Loss: 0.6990, Accuracy: 77.75%\n",
      "Epoch 7 Summary -> Avg. Loss: 0.6789, Accuracy: 78.07%\n",
      "Epoch 8 Summary -> Avg. Loss: 0.6695, Accuracy: 78.28%\n",
      "Epoch 9 Summary -> Avg. Loss: 0.6594, Accuracy: 78.58%\n",
      "Epoch 10 Summary -> Avg. Loss: 0.6532, Accuracy: 78.57%\n",
      "Epoch 11 Summary -> Avg. Loss: 0.6264, Accuracy: 79.31%\n",
      "Epoch 12 Summary -> Avg. Loss: 0.6039, Accuracy: 79.61%\n",
      "Epoch 13 Summary -> Avg. Loss: 0.5917, Accuracy: 79.87%\n",
      "Epoch 14 Summary -> Avg. Loss: 0.5667, Accuracy: 80.22%\n",
      "Epoch 15 Summary -> Avg. Loss: 0.5547, Accuracy: 80.76%\n",
      "Epoch 16 Summary -> Avg. Loss: 0.5364, Accuracy: 81.18%\n",
      "Epoch 17 Summary -> Avg. Loss: 0.5252, Accuracy: 81.62%\n",
      "Epoch 18 Summary -> Avg. Loss: 0.5006, Accuracy: 82.19%\n",
      "Epoch 19 Summary -> Avg. Loss: 0.4806, Accuracy: 82.48%\n",
      "Epoch 20 Summary -> Avg. Loss: 0.4726, Accuracy: 82.86%\n",
      "Epoch 21 Summary -> Avg. Loss: 0.4413, Accuracy: 83.58%\n",
      "Epoch 22 Summary -> Avg. Loss: 0.4209, Accuracy: 83.97%\n",
      "Epoch 23 Summary -> Avg. Loss: 0.4194, Accuracy: 84.36%\n",
      "Epoch 24 Summary -> Avg. Loss: 0.3934, Accuracy: 84.87%\n",
      "Epoch 25 Summary -> Avg. Loss: 0.3749, Accuracy: 85.68%\n",
      "Epoch 26 Summary -> Avg. Loss: 0.3703, Accuracy: 86.07%\n",
      "Epoch 27 Summary -> Avg. Loss: 0.3470, Accuracy: 86.40%\n",
      "Epoch 28 Summary -> Avg. Loss: 0.3343, Accuracy: 87.07%\n",
      "Epoch 29 Summary -> Avg. Loss: 0.3159, Accuracy: 87.55%\n",
      "Epoch 30 Summary -> Avg. Loss: 0.3016, Accuracy: 88.04%\n",
      "Epoch 31 Summary -> Avg. Loss: 0.2923, Accuracy: 88.51%\n",
      "Epoch 32 Summary -> Avg. Loss: 0.2723, Accuracy: 88.84%\n",
      "Epoch 33 Summary -> Avg. Loss: 0.2777, Accuracy: 89.35%\n",
      "Epoch 34 Summary -> Avg. Loss: 0.2626, Accuracy: 89.61%\n",
      "Epoch 35 Summary -> Avg. Loss: 0.2491, Accuracy: 90.06%\n",
      "Epoch 36 Summary -> Avg. Loss: 0.3182, Accuracy: 89.26%\n",
      "Epoch 37 Summary -> Avg. Loss: 0.2431, Accuracy: 90.39%\n",
      "Epoch 38 Summary -> Avg. Loss: 0.2218, Accuracy: 91.04%\n",
      "Epoch 39 Summary -> Avg. Loss: 0.2244, Accuracy: 91.03%\n",
      "Epoch 40 Summary -> Avg. Loss: 0.2260, Accuracy: 91.46%\n",
      "\n",
      "Total Train Time: 1h 7m 10s\n",
      "Evaluating model: MH_Bi_LSTM_hs128_l2_h8...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating (MH_Bi_LSTM_hs128_l2_h8):   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= MH_Bi_LSTM_hs128_l2_h8 =================\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Flare     0.9928    0.8834    0.9349      1878\n",
      "     C-Class     0.4848    0.9095    0.6325       210\n",
      "     M-Class     0.5667    0.8718    0.6869        39\n",
      "     X-Class     0.5000    0.7500    0.6000         4\n",
      "\n",
      "    accuracy                         0.8855      2131\n",
      "   macro avg     0.6361    0.8537    0.7136      2131\n",
      "weighted avg     0.9340    0.8855    0.8999      2131\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix:\n",
      " [[0.88338658 0.10596379 0.01064963 0.        ]\n",
      " [0.05714286 0.90952381 0.02380952 0.00952381]\n",
      " [0.         0.1025641  0.87179487 0.02564103]\n",
      " [0.         0.         0.25       0.75      ]]\n",
      "\n",
      "Key Metrics Summary:\n",
      "  balanced_accuracy   : 0.8537\n",
      "  roc_auc_weighted    : 0.9635\n",
      "  mcc                 : 0.6430\n",
      "  f1_macro            : 0.7136\n",
      "  f1_weighted         : 0.8999\n",
      "MH_Bi_LSTM_hs128_l2_h8.zip saved at /kaggle/working/MH_Bi_LSTM_hs128_l2_h8.zip | Size: 2.85 MB\n",
      "\n",
      "============================== Experiment 3/4: MH_Bi_LSTM_hs256_l3_h4 ==============================\n",
      "Using 2 GPUs via DataParallel!\n",
      "Training model: MH_Bi_LSTM_hs256_l3_h4 for 40 epochs...\n",
      "Starting training for 40 epochs on cuda.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86941cd305c40189c3ff50caf500dbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/40 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Summary -> Avg. Loss: 0.8735, Accuracy: 74.81%\n",
      "Epoch 2 Summary -> Avg. Loss: 0.8253, Accuracy: 75.97%\n",
      "Epoch 3 Summary -> Avg. Loss: 0.8000, Accuracy: 76.48%\n",
      "Epoch 4 Summary -> Avg. Loss: 0.7805, Accuracy: 76.13%\n",
      "Epoch 5 Summary -> Avg. Loss: 0.7546, Accuracy: 76.75%\n",
      "Epoch 6 Summary -> Avg. Loss: 0.7405, Accuracy: 76.95%\n",
      "Epoch 7 Summary -> Avg. Loss: 0.7243, Accuracy: 77.19%\n",
      "Epoch 8 Summary -> Avg. Loss: 0.7074, Accuracy: 77.56%\n",
      "Epoch 9 Summary -> Avg. Loss: 0.6996, Accuracy: 77.87%\n",
      "Epoch 10 Summary -> Avg. Loss: 0.7084, Accuracy: 77.55%\n",
      "Epoch 11 Summary -> Avg. Loss: 0.6620, Accuracy: 78.16%\n",
      "Epoch 12 Summary -> Avg. Loss: 0.6494, Accuracy: 78.34%\n",
      "Epoch 13 Summary -> Avg. Loss: 0.6411, Accuracy: 78.39%\n",
      "Epoch 14 Summary -> Avg. Loss: 0.6168, Accuracy: 78.68%\n",
      "Epoch 15 Summary -> Avg. Loss: 0.6082, Accuracy: 79.01%\n",
      "Epoch 16 Summary -> Avg. Loss: 0.5902, Accuracy: 79.40%\n",
      "Epoch 17 Summary -> Avg. Loss: 0.5608, Accuracy: 79.78%\n",
      "Epoch 18 Summary -> Avg. Loss: 0.5550, Accuracy: 80.06%\n",
      "Epoch 19 Summary -> Avg. Loss: 0.5258, Accuracy: 80.87%\n",
      "Epoch 20 Summary -> Avg. Loss: 0.5540, Accuracy: 80.71%\n",
      "Epoch 21 Summary -> Avg. Loss: 0.4955, Accuracy: 81.73%\n",
      "Epoch 22 Summary -> Avg. Loss: 0.4809, Accuracy: 82.34%\n",
      "Epoch 23 Summary -> Avg. Loss: 0.4688, Accuracy: 82.43%\n",
      "Epoch 24 Summary -> Avg. Loss: 0.4609, Accuracy: 83.02%\n",
      "Epoch 25 Summary -> Avg. Loss: 0.4585, Accuracy: 83.10%\n",
      "Epoch 26 Summary -> Avg. Loss: 0.4256, Accuracy: 83.48%\n",
      "Epoch 27 Summary -> Avg. Loss: 0.4098, Accuracy: 84.26%\n",
      "Epoch 28 Summary -> Avg. Loss: 0.4673, Accuracy: 83.80%\n",
      "Epoch 29 Summary -> Avg. Loss: 0.4126, Accuracy: 85.24%\n",
      "Epoch 30 Summary -> Avg. Loss: 0.3917, Accuracy: 85.24%\n",
      "Epoch 31 Summary -> Avg. Loss: 0.3622, Accuracy: 86.19%\n",
      "Epoch 32 Summary -> Avg. Loss: 0.3797, Accuracy: 86.09%\n",
      "Epoch 33 Summary -> Avg. Loss: 0.3603, Accuracy: 86.44%\n",
      "Epoch 34 Summary -> Avg. Loss: 0.3393, Accuracy: 87.05%\n",
      "Epoch 35 Summary -> Avg. Loss: 0.3384, Accuracy: 87.64%\n",
      "Epoch 36 Summary -> Avg. Loss: 0.3613, Accuracy: 87.08%\n",
      "Epoch 37 Summary -> Avg. Loss: 0.3391, Accuracy: 88.22%\n",
      "Epoch 38 Summary -> Avg. Loss: 0.3236, Accuracy: 88.45%\n",
      "Epoch 39 Summary -> Avg. Loss: 0.2931, Accuracy: 89.00%\n",
      "Epoch 40 Summary -> Avg. Loss: 0.2794, Accuracy: 89.40%\n",
      "\n",
      "Total Train Time: 4h 3m 15s\n",
      "Evaluating model: MH_Bi_LSTM_hs256_l3_h4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating (MH_Bi_LSTM_hs256_l3_h4):   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= MH_Bi_LSTM_hs256_l3_h4 =================\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Flare     0.9864    0.8908    0.9362      1878\n",
      "     C-Class     0.4793    0.8286    0.6073       210\n",
      "     M-Class     0.4516    0.7179    0.5545        39\n",
      "     X-Class     0.4000    1.0000    0.5714         4\n",
      "\n",
      "    accuracy                         0.8817      2131\n",
      "   macro avg     0.5793    0.8593    0.6674      2131\n",
      "weighted avg     0.9256    0.8817    0.8961      2131\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix:\n",
      " [[0.89084132 0.09584665 0.01224707 0.00106496]\n",
      " [0.1047619  0.82857143 0.05238095 0.01428571]\n",
      " [0.02564103 0.23076923 0.71794872 0.02564103]\n",
      " [0.         0.         0.         1.        ]]\n",
      "\n",
      "Key Metrics Summary:\n",
      "  balanced_accuracy   : 0.8593\n",
      "  roc_auc_weighted    : 0.9561\n",
      "  mcc                 : 0.6084\n",
      "  f1_macro            : 0.6674\n",
      "  f1_weighted         : 0.8961\n",
      "MH_Bi_LSTM_hs256_l3_h4.zip saved at /kaggle/working/MH_Bi_LSTM_hs256_l3_h4.zip | Size: 16.86 MB\n",
      "\n",
      "============================== Experiment 4/4: MH_Bi_LSTM_hs128_l1_h8 ==============================\n",
      "Using 2 GPUs via DataParallel!\n",
      "Training model: MH_Bi_LSTM_hs128_l1_h8 for 40 epochs...\n",
      "Starting training for 40 epochs on cuda.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45bf514d30f84940a5126bf4b30dbcb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|          | 0/40 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Summary -> Avg. Loss: 0.8437, Accuracy: 75.39%\n",
      "Epoch 2 Summary -> Avg. Loss: 0.8058, Accuracy: 75.87%\n",
      "Epoch 3 Summary -> Avg. Loss: 0.7956, Accuracy: 76.07%\n",
      "Epoch 4 Summary -> Avg. Loss: 0.7585, Accuracy: 76.18%\n",
      "Epoch 5 Summary -> Avg. Loss: 0.7309, Accuracy: 76.96%\n",
      "Epoch 6 Summary -> Avg. Loss: 0.7294, Accuracy: 77.12%\n",
      "Epoch 7 Summary -> Avg. Loss: 0.7146, Accuracy: 77.53%\n",
      "Epoch 8 Summary -> Avg. Loss: 0.7026, Accuracy: 77.85%\n",
      "Epoch 9 Summary -> Avg. Loss: 0.6824, Accuracy: 78.03%\n",
      "Epoch 10 Summary -> Avg. Loss: 0.6674, Accuracy: 78.24%\n",
      "Epoch 11 Summary -> Avg. Loss: 0.6504, Accuracy: 78.72%\n",
      "Epoch 12 Summary -> Avg. Loss: 0.6666, Accuracy: 78.64%\n",
      "Epoch 13 Summary -> Avg. Loss: 0.6438, Accuracy: 78.56%\n",
      "Epoch 14 Summary -> Avg. Loss: 0.6285, Accuracy: 79.07%\n",
      "Epoch 15 Summary -> Avg. Loss: 0.6261, Accuracy: 78.67%\n",
      "Epoch 16 Summary -> Avg. Loss: 0.6062, Accuracy: 79.34%\n",
      "Epoch 17 Summary -> Avg. Loss: 0.5959, Accuracy: 79.21%\n",
      "Epoch 18 Summary -> Avg. Loss: 0.5815, Accuracy: 79.56%\n",
      "Epoch 19 Summary -> Avg. Loss: 0.5646, Accuracy: 79.98%\n",
      "Epoch 20 Summary -> Avg. Loss: 0.5650, Accuracy: 80.04%\n",
      "Epoch 21 Summary -> Avg. Loss: 0.5537, Accuracy: 80.35%\n",
      "Epoch 22 Summary -> Avg. Loss: 0.5457, Accuracy: 80.25%\n",
      "Epoch 23 Summary -> Avg. Loss: 0.5802, Accuracy: 79.58%\n",
      "Epoch 24 Summary -> Avg. Loss: 0.5497, Accuracy: 80.23%\n",
      "Epoch 25 Summary -> Avg. Loss: 0.5232, Accuracy: 80.89%\n",
      "Epoch 26 Summary -> Avg. Loss: 0.5294, Accuracy: 80.86%\n",
      "Epoch 27 Summary -> Avg. Loss: 0.5234, Accuracy: 81.18%\n",
      "Epoch 28 Summary -> Avg. Loss: 0.6669, Accuracy: 79.12%\n",
      "Epoch 29 Summary -> Avg. Loss: 0.7259, Accuracy: 77.73%\n",
      "Epoch 30 Summary -> Avg. Loss: 0.6992, Accuracy: 77.68%\n",
      "Epoch 31 Summary -> Avg. Loss: 0.6776, Accuracy: 78.05%\n",
      "Epoch 32 Summary -> Avg. Loss: 0.6489, Accuracy: 78.46%\n",
      "Epoch 33 Summary -> Avg. Loss: 0.6555, Accuracy: 78.42%\n",
      "Epoch 34 Summary -> Avg. Loss: 0.7688, Accuracy: 76.16%\n",
      "Epoch 35 Summary -> Avg. Loss: 0.7810, Accuracy: 75.44%\n",
      "Epoch 36 Summary -> Avg. Loss: 0.7679, Accuracy: 75.69%\n",
      "Epoch 37 Summary -> Avg. Loss: 0.7610, Accuracy: 76.62%\n",
      "Epoch 38 Summary -> Avg. Loss: 0.7398, Accuracy: 76.51%\n",
      "Epoch 39 Summary -> Avg. Loss: 0.7480, Accuracy: 76.39%\n",
      "Epoch 40 Summary -> Avg. Loss: 0.7358, Accuracy: 76.64%\n",
      "\n",
      "Total Train Time: 0h 46m 51s\n",
      "Evaluating model: MH_Bi_LSTM_hs128_l1_h8...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating (MH_Bi_LSTM_hs128_l1_h8):   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= MH_Bi_LSTM_hs128_l1_h8 =================\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Flare     0.9744    0.8099    0.8846      1878\n",
      "     C-Class     0.2900    0.6476    0.4006       210\n",
      "     M-Class     0.1860    0.4103    0.2560        39\n",
      "     X-Class     0.2000    0.7500    0.3158         4\n",
      "\n",
      "    accuracy                         0.7865      2131\n",
      "   macro avg     0.4126    0.6544    0.4642      2131\n",
      "weighted avg     0.8911    0.7865    0.8243      2131\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix:\n",
      " [[0.80990415 0.16719915 0.02129925 0.00159744]\n",
      " [0.18571429 0.64761905 0.13809524 0.02857143]\n",
      " [0.02564103 0.48717949 0.41025641 0.07692308]\n",
      " [0.         0.         0.25       0.75      ]]\n",
      "\n",
      "Key Metrics Summary:\n",
      "  balanced_accuracy   : 0.6544\n",
      "  roc_auc_weighted    : 0.9059\n",
      "  mcc                 : 0.3991\n",
      "  f1_macro            : 0.4642\n",
      "  f1_weighted         : 0.8243\n",
      "MH_Bi_LSTM_hs128_l1_h8.zip saved at /kaggle/working/MH_Bi_LSTM_hs128_l1_h8.zip | Size: 1.45 MB\n",
      "\n",
      "============================== FINAL EXPERIMENT REPORT ==============================\n",
      "Total experiment time: 530.83 minutes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>hidden_size</th>\n",
       "      <th>num_heads</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>roc_auc_weighted</th>\n",
       "      <th>mcc</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>training_time_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MH_Bi_LSTM_hs128_l2_h8</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8537</td>\n",
       "      <td>0.9635</td>\n",
       "      <td>0.6430</td>\n",
       "      <td>0.7136</td>\n",
       "      <td>0.8999</td>\n",
       "      <td>67.1872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MH_Bi_LSTM_hs256_l3_h4</td>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>0.9561</td>\n",
       "      <td>0.6084</td>\n",
       "      <td>0.6674</td>\n",
       "      <td>0.8961</td>\n",
       "      <td>243.2759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MH_Bi_LSTM_hs256_l2_h4</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>0.8302</td>\n",
       "      <td>0.9251</td>\n",
       "      <td>0.4653</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.8374</td>\n",
       "      <td>173.4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MH_Bi_LSTM_hs128_l1_h8</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>0.6544</td>\n",
       "      <td>0.9059</td>\n",
       "      <td>0.3991</td>\n",
       "      <td>0.4642</td>\n",
       "      <td>0.8243</td>\n",
       "      <td>46.8569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 run_name  num_layers  hidden_size  num_heads  \\\n",
       "0  MH_Bi_LSTM_hs128_l2_h8           2          128          8   \n",
       "1  MH_Bi_LSTM_hs256_l3_h4           3          256          4   \n",
       "2  MH_Bi_LSTM_hs256_l2_h4           2          256          4   \n",
       "3  MH_Bi_LSTM_hs128_l1_h8           1          128          8   \n",
       "\n",
       "   balanced_accuracy  roc_auc_weighted    mcc  f1_macro  f1_weighted  \\\n",
       "0             0.8537            0.9635 0.6430    0.7136       0.8999   \n",
       "1             0.8593            0.9561 0.6084    0.6674       0.8961   \n",
       "2             0.8302            0.9251 0.4653    0.5500       0.8374   \n",
       "3             0.6544            0.9059 0.3991    0.4642       0.8243   \n",
       "\n",
       "   training_time_min  \n",
       "0            67.1872  \n",
       "1           243.2759  \n",
       "2           173.4759  \n",
       "3            46.8569  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "results_log = []\n",
    "total_start_time = time.time()\n",
    "\n",
    "for i, config in enumerate(experiments):\n",
    "    print(f\"\\n{'='*30} Experiment {i+1}/{len(experiments)}: {config['run_name']} {'='*30}\")\n",
    "    \n",
    "    experiment_start_time = time.time()\n",
    "    \n",
    "    \n",
    "    model = MultiHeadBiLSTM(\n",
    "        input_size=len(features),\n",
    "        hidden_size=config[\"hidden_size\"],\n",
    "        num_classes=len(class_names),\n",
    "        num_layers=config[\"num_layers\"],\n",
    "        num_heads=config[\"heads\"]\n",
    "    )\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(f\"Using {torch.cuda.device_count()} GPUs via DataParallel!\")\n",
    "        model = nn.DataParallel(model)\n",
    "        \n",
    "    # model = unzip_and_load_model(model, config['run_name'])\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "    \n",
    "    print(f\"Training model: {config['run_name']} for {config['epochs']} epochs...\")\n",
    "    training(model, device, criterion, optimizer, train, train_epochs=config[\"epochs\"])\n",
    "    \n",
    "    print(f\"Evaluating model: {config['run_name']}...\")\n",
    "    eval_metrics = eval_detailed(model, device, dev, report_title=config['run_name'])\n",
    "    \n",
    "    experiment_time = time.time() - experiment_start_time\n",
    "    save_model_as_zip(model, model_name=config['run_name'])\n",
    "    \n",
    "    run_result = {\n",
    "        \"run_name\": config[\"run_name\"],\n",
    "        \"num_layers\": config[\"num_layers\"],\n",
    "        \"hidden_size\": config[\"hidden_size\"],\n",
    "        \"num_heads\": config[\"heads\"],\n",
    "        **eval_metrics,\n",
    "        \"training_time_min\": experiment_time / 60\n",
    "    }\n",
    "    results_log.append(run_result)\n",
    "    \n",
    "    pd.DataFrame(results_log).to_csv(\"multihead_experiment_report_intermediate.csv\", index=False)\n",
    "\n",
    "\n",
    "print(f\"\\n{'='*30} FINAL EXPERIMENT REPORT {'='*30}\")\n",
    "total_run_time = time.time() - total_start_time\n",
    "print(f\"Total experiment time: {total_run_time/60:.2f} minutes\")\n",
    "\n",
    "results_df = pd.DataFrame(results_log)\n",
    "results_df = results_df.sort_values(by=\"mcc\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "display(results_df)\n",
    "\n",
    "results_df.to_csv(\"multihead_experiment_report.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Evaluation of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-24T07:10:06.493822Z",
     "iopub.status.busy": "2025-11-24T07:10:06.493194Z",
     "iopub.status.idle": "2025-11-24T07:10:07.959590Z",
     "shell.execute_reply": "2025-11-24T07:10:07.958887Z",
     "shell.execute_reply.started": "2025-11-24T07:10:06.493789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating (LSTM_Bi_dot):   0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================= LSTM_Bi_dot =================\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Flare     0.9902    0.9169    0.9522      1878\n",
      "     C-Class     0.5770    0.9095    0.7061       210\n",
      "     M-Class     0.6296    0.8718    0.7312        39\n",
      "     X-Class     0.5714    1.0000    0.7273         4\n",
      "\n",
      "    accuracy                         0.9155      2131\n",
      "   macro avg     0.6921    0.9246    0.7792      2131\n",
      "weighted avg     0.9421    0.9155    0.9235      2131\n",
      "\n",
      "\n",
      "Normalized Confusion Matrix:\n",
      " [[0.91693291 0.07348243 0.00958466 0.        ]\n",
      " [0.07619048 0.90952381 0.00952381 0.0047619 ]\n",
      " [0.02564103 0.05128205 0.87179487 0.05128205]\n",
      " [0.         0.         0.         1.        ]]\n",
      "\n",
      "Key Metrics Summary:\n",
      "  balanced_accuracy   : 0.9246\n",
      "  roc_auc_weighted    : 0.9730\n",
      "  mcc                 : 0.7031\n",
      "  f1_macro            : 0.7792\n",
      "  f1_weighted         : 0.9235\n"
     ]
    }
   ],
   "source": [
    "model = AttentiveLSTM(\n",
    "            input_size=len(features),\n",
    "            hidden_size=128,\n",
    "            num_classes=len(class_names),\n",
    "            num_layers=2,\n",
    "            attention=\"dot\",\n",
    "            bidirectional=True\n",
    "        )\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torch.nn.DataParallel(model) \n",
    "model_path = \"/kaggle/input/lstm-bi-dot/pytorch/default/1/LSTM_Bi_dot.pth\"\n",
    "model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "model.to(device)\n",
    "eval_metrics = eval_detailed(model, device, test, report_title=\"LSTM_Bi_dot\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8696148,
     "sourceId": 13675864,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 513304,
     "modelInstanceId": 498011,
     "sourceId": 658672,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
